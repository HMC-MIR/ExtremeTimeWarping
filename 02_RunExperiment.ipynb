{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Alignment Code for DTW"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "The Cython extension is already loaded. To reload it, use:\n",
                  "  %reload_ext Cython\n"
               ]
            }
         ],
         "source": [
            "%matplotlib inline\n",
            "%load_ext Cython"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import librosa as lb\n",
            "import os.path\n",
            "from pathlib import Path\n",
            "import pickle\n",
            "import multiprocessing\n",
            "import time\n",
            "import gc\n",
            "import math\n",
            "import import_ipynb\n",
            "from datetime import timedelta"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Cumulative Cost, Steps and Path"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "%%cython\n",
            "import numpy as np\n",
            "cimport numpy as np\n",
            "cimport cython\n",
            "\n",
            "import sys\n",
            "import time\n",
            "\n",
            "DTYPE_INT32 = np.int32\n",
            "ctypedef np.int32_t DTYPE_INT32_t\n",
            "\n",
            "DTYPE_FLOAT = np.float64\n",
            "ctypedef np.float64_t DTYPE_FLOAT_t\n",
            "\n",
            "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
            "\n",
            "# careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
            "@cython.cdivision(True) # prevent checks on ZeroDivisionError\n",
            "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
            "@cython.wraparound(False) # prevents extra checks that are required for calling a list relative to the end like mylist[-5])\n",
            "@cython.nonecheck(False) # prevents checks on isNone\n",
            "def DTW_Cost_To_AccumCostAndSteps(Cin, parameter, WarpMax=None):\n",
            "    '''\n",
            "    Inputs\n",
            "        C: The cost Matrix\n",
            "    '''\n",
            "\n",
            "    '''\n",
            "    Section for checking and catching errors in the inputs\n",
            "    '''\n",
            "\n",
            "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] C\n",
            "    try:\n",
            "        C = np.array(Cin, dtype=DTYPE_FLOAT)\n",
            "    except TypeError:\n",
            "        print(bcolors.FAIL + \"FAILURE: The type of the cost matrix is wrong - please pass in a 2-d numpy array\" + bcolors.ENDC)\n",
            "        return [-1, -1, -1]\n",
            "    except ValueError:\n",
            "        print(bcolors.FAIL + \"FAILURE: The type of the elements in the cost matrix is wrong - please have each element be a float (perhaps you passed in a matrix of ints?)\" + bcolors.ENDC)\n",
            "        return [-1, -1, -1]\n",
            "\n",
            "    cdef np.ndarray[np.uint32_t, ndim=1] dn\n",
            "    cdef np.ndarray[np.uint32_t, ndim=1] dm\n",
            "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=1] dw\n",
            "    # make sure dn, dm, and dw are setup\n",
            "    # dn loading and exception handling\n",
            "    if ('dn' in parameter.keys()):\n",
            "        try:\n",
            "            dn = np.array(parameter['dn'], dtype=np.uint32)\n",
            "        except TypeError:\n",
            "            print(bcolors.FAIL + \"FAILURE: The type of dn (row steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
            "            return [-1, -1, -1]\n",
            "        except ValueError:\n",
            "            print(bcolors.FAIL + \"The type of the elements in dn (row steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
            "            return [-1, -1, -1]\n",
            "    else:\n",
            "        dn = np.array([1, 1, 0], dtype=np.uint32)\n",
            "    # dm loading and exception handling\n",
            "    if 'dm'  in parameter.keys():\n",
            "        try:\n",
            "            dm = np.array(parameter['dm'], dtype=np.uint32)\n",
            "        except TypeError:\n",
            "            print(bcolors.FAIL + \"FAILURE: The type of dm (col steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
            "            return [-1, -1, -1]\n",
            "        except ValueError:\n",
            "            print(bcolors.FAIL + \"FAILURE: The type of the elements in dm (col steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
            "            return [-1, -1, -1]\n",
            "    else:\n",
            "        print(bcolors.FAIL + \"dm (col steps) was not passed in (gave default value [1,0,1]) \" + bcolors.ENDC)\n",
            "        dm = np.array([1, 0, 1], dtype=np.uint32)\n",
            "    # dw loading and exception handling\n",
            "    if 'dw'  in parameter.keys():\n",
            "        try:\n",
            "            dw = np.array(parameter['dw'], dtype=DTYPE_FLOAT)\n",
            "        except TypeError:\n",
            "            print(bcolors.FAIL + \"FAILURE: The type of dw (step weights) is wrong - please pass in a 1-d numpy array that holds floats\" + bcolors.ENDC)\n",
            "            return [-1, -1, -1]\n",
            "        except ValueError:\n",
            "            print(bcolors.FAIL + \"FAILURE:The type of the elements in dw (step weights) is wrong - please have each element be a float (perhaps you passed ints or a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.float64)\" + bcolors.ENDC)\n",
            "            return [-1, -1, -1]\n",
            "    else:\n",
            "        dw = np.array([1, 1, 1], dtype=DTYPE_FLOAT)\n",
            "        print(bcolors.FAIL + \"dw (step weights) was not passed in (gave default value [1,1,1]) \" + bcolors.ENDC)\n",
            "    \n",
            "    '''\n",
            "    Section where types are given to the variables we're going to use \n",
            "    '''\n",
            "    # create matrices to store our results (D and E)\n",
            "    cdef DTYPE_INT32_t numRows = C.shape[0] # only works with np arrays, use np.shape(x) will work on lists? want to force to use np though?\n",
            "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
            "    cdef DTYPE_INT32_t numDifSteps = np.size(dw)\n",
            "\n",
            "    cdef unsigned int maxRowStep = max(dn)\n",
            "    cdef unsigned int maxColStep = max(dm)\n",
            "\n",
            "    cdef np.ndarray[np.uint32_t, ndim=2] steps = np.zeros((numRows,numCols), dtype=np.uint32)\n",
            "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((maxRowStep + numRows, maxColStep + numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
            "\n",
            "    cdef DTYPE_FLOAT_t bestCost\n",
            "    cdef DTYPE_INT32_t bestCostIndex\n",
            "    cdef DTYPE_FLOAT_t costForStep\n",
            "    cdef unsigned int row, col\n",
            "    cdef unsigned int stepIndex\n",
            "\n",
            "    '''\n",
            "    The start of the actual algorithm, now that all our variables are set up\n",
            "    '''\n",
            "    # initializing the cost matrix - depends on whether its subsequence DTW\n",
            "    # essentially allow us to hop on the bottom anywhere (so could start partway through one of the signals)\n",
            "    if parameter['SubSequence']:\n",
            "        for col in range(numCols):\n",
            "            accumCost[maxRowStep, col + maxColStep] = C[0, col]\n",
            "    else:\n",
            "        accumCost[maxRowStep, maxColStep] = C[0,0]\n",
            "\n",
            "    # ADDED\n",
            "    remove_x = False\n",
            "    remove_y = False\n",
            "\n",
            "    # filling the accumulated cost matrix\n",
            "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
            "        if WarpMax and row % WarpMax == 0 and row > 1: # ADDED\n",
            "            remove_x = True\n",
            "\n",
            "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
            "            if WarpMax and col % WarpMax == 0: # ADDED\n",
            "                remove_y = True\n",
            "            \n",
            "            bestCost = accumCost[<unsigned int>row, <unsigned int>col] # initialize with what's there - so if is an entry point, then can start low\n",
            "            bestCostIndex = 0\n",
            "            # go through each step, find the best one\n",
            "            for stepIndex in range(numDifSteps):\n",
            "                if remove_x and dn[(stepIndex)]==1 and dm[(stepIndex)]==0: # ADDED\n",
            "                    continue\n",
            "                if remove_y and dm[(stepIndex)]==1 and dn[(stepIndex)]==0:\n",
            "                    continue\n",
            "                costForStep = accumCost[<unsigned int>((row - dn[(stepIndex)])), <unsigned int>((col - dm[(stepIndex)]))] + dw[stepIndex] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
            "                if costForStep < bestCost:\n",
            "                    bestCost = costForStep\n",
            "                    bestCostIndex = stepIndex\n",
            "            \n",
            "            # save the best cost and best cost index\n",
            "            accumCost[row, col] = bestCost\n",
            "            steps[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)] = bestCostIndex\n",
            "            remove_y = False\n",
            "        remove_x = False\n",
            "\n",
            "    # return the accumulated cost along with the matrix of steps taken to achieve that cost\n",
            "    return [accumCost[maxRowStep:, maxColStep:], steps]\n",
            "\n",
            "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
            "def DTW_GetPath(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
            "    '''\n",
            "    Parameter should have: 'dn', 'dm', 'dw', 'SubSequence'\n",
            "    '''\n",
            "\n",
            "    cdef np.ndarray[unsigned int, ndim=1] dn\n",
            "    cdef np.ndarray[unsigned int, ndim=1] dm\n",
            "    cdef np.uint8_t subseq\n",
            "    cdef np.int32_t startCol # added\n",
            "    # make sure dn, dm, and dw are setup\n",
            "    if ('dn'  in parameter.keys()):\n",
            "        dn = parameter['dn']\n",
            "    else:\n",
            "        dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
            "    if 'dm'  in parameter.keys():\n",
            "        dm = parameter['dm']\n",
            "    else:\n",
            "        dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
            "    if 'SubSequence' in parameter.keys():\n",
            "        subseq = parameter['SubSequence']\n",
            "    else:\n",
            "        subseq = 0\n",
            "    \n",
            "    # added START\n",
            "    if 'startCol' in parameter.keys(): \n",
            "        startCol = parameter['startCol']\n",
            "    else:\n",
            "        startCol = -1\n",
            "    # added END\n",
            "\n",
            "    cdef np.uint32_t numRows\n",
            "    cdef np.uint32_t numCols\n",
            "    cdef np.uint32_t curRow\n",
            "    cdef np.uint32_t curCol\n",
            "    cdef np.uint32_t endCol\n",
            "    cdef DTYPE_FLOAT_t endCost\n",
            "\n",
            "    numRows = accumCost.shape[0]\n",
            "    numCols = accumCost.shape[1]\n",
            "\n",
            "    # either start at the far corner (non sub-sequence)\n",
            "    # or start at the lowest cost entry in the last row (sub-sequence)\n",
            "    # where all of the signal along the row has been used, but only a \n",
            "    # sub-sequence of the signal along the columns has to be used\n",
            "    curRow = numRows - 1\n",
            "    if subseq:\n",
            "        curCol = np.argmin(accumCost[numRows - 1, :])\n",
            "    else:\n",
            "        curCol = numCols - 1\n",
            "        \n",
            "    # added - if specified, overrides above\n",
            "    if startCol >= 0:\n",
            "        curCol = startCol\n",
            "\n",
            "    endCol = curCol\n",
            "    endCost = accumCost[curRow, curCol]\n",
            "\n",
            "    cdef np.uint32_t curRowStep\n",
            "    cdef np.uint32_t curColStep\n",
            "    cdef np.uint32_t curStepIndex\n",
            "\n",
            "    cdef np.ndarray[np.uint32_t, ndim=2] path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
            "    path[0, 0] = curRow\n",
            "    path[1, 0] = curCol\n",
            "\n",
            "    cdef np.uint32_t stepsInPath = 1 # starts at one, we add in one before looping\n",
            "    cdef np.uint32_t stepIndex = 0\n",
            "    cdef np.int8_t done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
            "\n",
            "    # KEEP TRACK OF STEPS TAKEN BY ALGORITHM\n",
            "    track_steps_dict = {i:0 for i in range(0,len(dn))}\n",
            "\n",
            "    while not done:\n",
            "        if accumCost[curRow, curCol] == MAX_FLOAT:\n",
            "            print('A path is not possible')\n",
            "            break\n",
            "\n",
            "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
            "        # or just the bottom (sub-sequence)\n",
            "        # find the step size\n",
            "        curStepIndex = stepsForCost[curRow, curCol]\n",
            "        track_steps_dict[curStepIndex] += 1 # KEEP TRACK OF STEPS -- update track_steps_dict\n",
            "        curRowStep = dn[curStepIndex]\n",
            "        curColStep = dm[curStepIndex]\n",
            "        # backtrack by 1 step\n",
            "        curRow = curRow - curRowStep\n",
            "        curCol = curCol - curColStep\n",
            "        # add your new location onto the path\n",
            "        path[0, stepsInPath] = curRow\n",
            "        path[1, stepsInPath] = curCol\n",
            "        stepsInPath = stepsInPath + 1\n",
            "        # check to see if you're done\n",
            "        done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
            "\n",
            "    # reverse the path (a matrix with two rows) and return it\n",
            "    return [np.fliplr(path[:, 0:stepsInPath]), endCol, endCost], track_steps_dict\n",
            "\n",
            "class bcolors:\n",
            "    HEADER = '\\033[95m'\n",
            "    OKBLUE = '\\033[94m'\n",
            "    OKGREEN = '\\033[92m'\n",
            "    WARNING = '\\033[93m'\n",
            "    FAIL = '\\033[91m'\n",
            "    ENDC = '\\033[0m'\n",
            "    BOLD = '\\033[1m'\n",
            "    UNDERLINE = '\\033[4m'"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## AlignDTW"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "def alignDTW(featfile1, featfile2, steps, weights, method, WarpMax, outfile, profile, subsequence):\n",
            "    \n",
            "    if 'adaptiveHop' in method:\n",
            "        base, version = os.path.split(featfile1)\n",
            "        version = version.replace(\".npy\", \"\")\n",
            "        base, mazurka = os.path.split(base)\n",
            "        base = os.path.split(os.path.split(base)[0])[0]\n",
            "        wav_file = Path(f\"{base}/wav_22050_mono/{mazurka}/{version}\").with_suffix(\".wav\")\n",
            "        y, sr = lb.core.load(wav_file, sr=22050)\n",
            "        length1 = str(featfile1)[:str(featfile1).index(os.sep)].split(\"_x\")[-1]\n",
            "        length2 = str(featfile2)[:str(featfile2).index(os.sep)].split(\"_x\")[-1]\n",
            "        factor = float(length1) / float(length2)\n",
            "        hop_length = round(512 * factor) # / 64.0) * 64\n",
            "        F1 = lb.feature.chroma_stft(y, sr=sr, hop_length=hop_length, norm=2)\n",
            "        F2 = np.load(featfile2) # 12 x M\n",
            "        N, M = F1.shape[1], F2.shape[1]\n",
            "    else:\n",
            "        F1 = np.load(featfile1) # 12 x N\n",
            "        F2 = np.load(featfile2) # 12 x M\n",
            "        # we assume that N >= M \n",
            "        N, M = F1.shape[1], F2.shape[1]\n",
            "    times = []\n",
            "    times.append(time.time())\n",
            "    if method == \"downsampleQuantized\" or \"adaptiveHopDownsample\" in method:\n",
            "        # we wish to only select M columns of of F1 to get (12 x M)\n",
            "        index = [int(round(x)) for x in np.linspace(0, N-1, M)]\n",
            "        F1 = F1[:, index]\n",
            "    elif method == \"downsampleInterpolate\":\n",
            "        # we want to multiply matrix (12 x N) by (N x M) to get (12 x M)\n",
            "        transform = np.zeros((N, M))\n",
            "        index = np.linspace(0, N-1, M) # M indices evenly spaced between [0, N-1]\n",
            "        for col, index in enumerate(index):\n",
            "            # at column m, insert weight RIGHT at position ROW and LEFT at position ROW+1\n",
            "            row = int(index)\n",
            "            right = index - int(index)\n",
            "            left = 1 - right\n",
            "            # if we are at the last row, insert weight 1\n",
            "            if row + 1 == N:\n",
            "                transform[row, col] = 1\n",
            "                continue\n",
            "            transform[row, col] = left\n",
            "            transform[row+1, col] = right\n",
            "        F1 = F1 @ transform\n",
            "    elif method == \"upsampleQuantized\":\n",
            "        index = [int(x) for x in np.linspace(0, M-1, N)]\n",
            "        F2 = F2[:, index] \n",
            "    elif method == \"upsampleInterpolate\":\n",
            "        # we want to multiply matrix (12 x M) by (M x N) to get (12 x N)\n",
            "        transform = np.zeros((M, N))\n",
            "        index = np.linspace(0, M-1, N) # N indices evenly spaced between [0, M-1]\n",
            "        for col, index in enumerate(index):\n",
            "            # at column N, insert weight RIGHT at position ROW and LEFT at position ROW+1\n",
            "            row = int(index)\n",
            "            right = index - int(index)\n",
            "            left = 1 - right\n",
            "            # if we are at the last row, insert weight 1\n",
            "            if row + 1 == M:\n",
            "                transform[row, col] = 1\n",
            "                continue\n",
            "            transform[row, col] = left\n",
            "            transform[row+1, col] = right\n",
            "        F2 = F2 @ transform\n",
            "    elif method == \"adaptiveWeight1\":\n",
            "        weights = np.array([N/M, 1])\n",
            "    elif method == \"adaptiveWeight2\":\n",
            "        weights = np.array([N/M, 1, 1 + N/M])\n",
            "\n",
            "    C = 1 - F1.T @ F2 # cost distance metric\n",
            "    times.append(time.time())\n",
            "\n",
            "    dn = steps[:,0].astype(np.uint32)\n",
            "    dm = steps[:,1].astype(np.uint32)\n",
            "    parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': subsequence}\n",
            "    [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters, WarpMax)\n",
            "    times.append(time.time())\n",
            "    [wp, endCol, endCost], track_steps_dict = DTW_GetPath(D, s, parameters)\n",
            "    times.append(time.time())\n",
            "\n",
            "    if method == \"downsampleQuantized\" or method == \"downsampleInterpolate\":\n",
            "        wp[0] = wp[0] * N / M\n",
            "    elif method == \"upsampleQuantized\" or method == \"upsampleInterpolate\":\n",
            "        wp[1] = wp[1] * M / N\n",
            "    elif 'adaptiveHop' in method:\n",
            "        wp[0] = wp[0] * factor\n",
            "    \n",
            "    if outfile:\n",
            "        pickle.dump(wp, open(outfile, 'wb'))\n",
            "        \n",
            "    # KEEP TRACK OF STEPS TAKEN BY ALGORITHM\n",
            "    steps_outfile = str(outfile).replace(\".pkl\",\"_steps.pkl\") # make outfile for steps tracking\n",
            "    track_steps_dict['steps'] = steps\n",
            "    with open(steps_outfile, 'wb') as fp:\n",
            "        pickle.dump(track_steps_dict, fp)\n",
            "    # profile will mark times [before_accum_cost, after_accum_cost, after_path]\n",
            "    return wp, np.diff(times) if profile else wp"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "# query_list = \"cfg_files/filelist.train_toy.txt\"\n",
            "# featdir1 = Path(\"Mazurkas_median_x1.260/features/clean\")\n",
            "# featdir2 = Path(\"Mazurkas_median_x1.000/features/clean\")\n",
            "# outdir = Path(\"experiments_test/train_toy.x1260.x1000.DTW1_adaptiveHop\")\n",
            "# n_cores = 40\n",
            "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "# weights = np.array([2,3,3])\n",
            "# method = 'adaptiveHop'\n",
            "# warpMax = None\n",
            "# profile = None\n",
            "# subsequence = False\n",
            "\n",
            "# featfile1 = Path(\"Mazurkas_median_x1.260/features/clean/Chopin_Op017No4/Chopin_Op017No4_Fou-1978_pid9071-20\").with_suffix('.npy')\n",
            "# featfile2 = Path(\"Mazurkas_median_x1.000/features/clean/Chopin_Op017No4/Chopin_Op017No4_Magaloff-1977_pid5667267b-10\").with_suffix('.npy')\n",
            "# outfile = Path(\"experiments_test/train_toy.x1260.x1000.DTW1_adaptiveHop/Chopin_Op017No4_Fou-1978_pid9071-20__Chopin_Op017No4_Magaloff-1977_pid5667267b-10\").with_suffix('.pkl')\n",
            "\n",
            "# alignDTW(featfile1, featfile2, steps, weights, method, warpMax, outfile, profile, subsequence)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [],
         "source": [
            "def alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, method, warpMax, profile, subsequence):\n",
            "    outdir.mkdir(parents=True, exist_ok=True)\n",
            "    inputs = []\n",
            "    with open(querylist, 'r') as f:\n",
            "        for line in f:\n",
            "            parts = line.strip().split(' ')\n",
            "            assert len(parts) == 2\n",
            "            featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
            "            featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
            "            queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
            "            outfile = (outdir / queryid).with_suffix('.pkl')\n",
            "            if os.path.exists(outfile):\n",
            "                print(f\"Skipping {outfile}\")\n",
            "            inputs.append((featfile1, featfile2, steps, weights, method, warpMax, outfile, profile, subsequence))\n",
            "    # process files in parallel\n",
            "    pool = multiprocessing.Pool(processes = n_cores)\n",
            "    pool.starmap(alignDTW, inputs)\n",
            "    return"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "##### Single working example"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [],
         "source": [
            "# dir1 = Path('Mazurkas_median_x2.000///features/clean/Chopin_Op017No4/Chopin_Op017No4_Magaloff-1977_pid5667267b-10.npy')\n",
            "# dir2 = Path('Mazurkas_median_x0.630/features/clean/Chopin_Op017No4/Chopin_Op017No4_Fou-1978_pid9071-20.npy')\n",
            "# F1 = np.load(dir1) # 12 x N\n",
            "# F2 = np.load(dir2) # 12 x M\n",
            "# N, M = F1.shape[1], F2.shape[1]"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "##### Testing each method"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "# n_cores, steps, weights, downsample, alignment_function = get_DTW_settings('DTW1')\n",
            "# dir1 = Path('Mazurkas_median_x2.000///features/clean/Chopin_Op017No4/Chopin_Op017No4_Magaloff-1977_pid5667267b-10.npy')\n",
            "# dir2 = Path('Mazurkas_median_x0.630/features/clean/Chopin_Op017No4/Chopin_Op017No4_Fou-1978_pid9071-20.npy')\n",
            "# outfile = Path(\"experiments_test/train_toy.x2000.x0630.DTW/Chopin_Op017No4_Magaloff-1977_pid5667267b-10__Chopin_Op017No4_Fou-1978_pid9071-20.pkl\")\n",
            "# alignDTW(dir1, dir2, steps, weights, \"downsampleQuantized\", None, outfile, True)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Get Settings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_settings(algorithm):\n",
            "    \"\"\"\n",
            "    Given an algorithm, \n",
            "        Return n_cores, steps, weights, method, warpMax\n",
            "    \"\"\"\n",
            "    n_cores = 24 # multiprocessing.cpu_count()\n",
            "    steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "    weights = np.array([2,3,3])\n",
            "    method = \"DTW\"\n",
            "    warpMax = None\n",
            "    subsequence = False\n",
            "\n",
            "    if algorithm == 'DTW2':\n",
            "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "        weights = np.array([1,2,2])\n",
            "    elif algorithm == 'DTW3':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "    elif algorithm == 'DTW4':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,1])\n",
            "    elif algorithm == 'DTW5':\n",
            "        steps = np.array([0,1,1,0]).reshape((-1,2))\n",
            "        weights = np.array([1,1])\n",
            "    elif algorithm == 'DTW1_add3':\n",
            "        steps = np.array([1,1,1,2,2,1,1,3,3,1]).reshape((-1,2))\n",
            "        weights = np.array([2,3,3,4,4])\n",
            "    elif algorithm == 'DTW1_add4':\n",
            "        steps = np.array([1,1,1,2,2,1,1,3,3,1,1,4,4,1]).reshape((-1,2))\n",
            "        weights = np.array([2,3,3,4,4,5,5])\n",
            "\n",
            "    elif algorithm == 'DTW1_downsampleQuantized':\n",
            "        method = \"downsampleQuantized\"\n",
            "    elif algorithm == 'DTW1_downsampleInterpolate':\n",
            "        method = \"downsampleInterpolate\"\n",
            "    elif algorithm == 'DTW1_upsampleQuantized':\n",
            "        method = \"upsampleQuantized\"\n",
            "    elif algorithm == 'DTW1_upsampleInterpolate':\n",
            "        method = \"upsampleInterpolate\"\n",
            "    elif algorithm == 'DTW_adaptiveWeight1':\n",
            "        steps = np.array([0,1,1,0]).reshape((-1,2))\n",
            "        method = \"adaptiveWeight1\"\n",
            "    elif algorithm == 'DTW_adaptiveWeight2':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        method = \"adaptiveWeight2\"\n",
            "    \n",
            "    elif algorithm == 'DTW_selectiveTransitions2':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 2\n",
            "    elif algorithm == 'DTW_selectiveTransitions3':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 3\n",
            "    elif algorithm == 'DTW_selectiveTransitions4':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 4\n",
            "    elif algorithm == 'DTW_selectiveTransitions5':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 5\n",
            "    \n",
            "    elif algorithm == 'SubDTW1':\n",
            "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW2':\n",
            "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "        weights = np.array([2,3,3])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW3':\n",
            "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "        weights = np.array([1,2,2])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW4':\n",
            "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,1])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW5':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([0,1,1])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW6':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,1])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW7':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        subsequence = True\n",
            "    \n",
            "    elif algorithm == 'SubDTW3_add3':\n",
            "        steps = np.array([1,1,1,2,2,1,1,3,3,1]).reshape((-1,2))\n",
            "        weights = np.array([1,2,2,1,3])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW6_add3':\n",
            "        steps = np.array([0,1,1,0,1,1,1,3,3,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,1,1,3])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW3_add4':\n",
            "        steps = np.array([1,1,1,2,2,1,1,3,3,1,1,4,4,1]).reshape((-1,2))\n",
            "        weights = np.array([1,2,2,1,3,1,4])\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW6_add4':\n",
            "        steps = np.array([0,1,1,0,1,1,1,3,3,1,1,4,4,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,1,1,3,1,4])\n",
            "        subsequence = True\n",
            "    \n",
            "    elif algorithm == 'SubDTW_selectiveTransitions2':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 2\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW_selectiveTransitions3':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 3\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW_selectiveTransitions4':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 4\n",
            "        subsequence = True\n",
            "    elif algorithm == 'SubDTW_selectiveTransitions5':\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "        warpMax = 5\n",
            "        subsequence = True\n",
            "        \n",
            "    elif algorithm == 'DTW1_adaptiveHop':\n",
            "        method = 'adaptiveHop'\n",
            "    elif algorithm == 'DTW1_adaptiveHopDownsample':\n",
            "        method = 'adaptiveHopDownsample'\n",
            "        \n",
            "    elif algorithm == 'DTW3_adaptiveHop':\n",
            "        method = 'adaptiveHop'\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "    elif algorithm == 'DTW3_adaptiveHopDownsample':\n",
            "        method = 'adaptiveHopDownsample'\n",
            "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
            "        weights = np.array([1,1,2])\n",
            "\n",
            "    return n_cores, steps, weights, method, warpMax, subsequence"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Run Benchmarks"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [],
         "source": [
            "def single_benchmark(filelist, timing1, timing2, algorithm, profile, outdir='experiments_test'):\n",
            "    \"\"\"\n",
            "    Inputs: 'train_toy', 'Mazurkas_median_x1.000', 'Mazurkas_median_x1.000', 'DTW1'\n",
            "    Output: Run specified DTW algorithm for a single system description\n",
            "    \"\"\"\n",
            "    query_list = f'cfg_files/filelist.{filelist}.txt' # make 'train_toy' to actual file path --> 'cfg_files/filelist.train_toy.txt'\n",
            "    featdir1 = Path(f\"Mazurkas_median_{timing1}/features/clean\")\n",
            "    featdir2 = Path(f\"Mazurkas_median_{timing2}/features/clean\")\n",
            "    timing1 = timing1.replace('.','').replace('_subseq20','') # change for outdir\n",
            "    timing2 = timing2.replace('.','')\n",
            "    outdir = Path(f'{outdir}/{filelist}.{timing1}.{timing2}.{algorithm}')\n",
            "    # get alignment settings based on specified alignment type\n",
            "    n_cores, steps, weights, method, warpMax, subsequence = get_settings(algorithm)\n",
            "    alignDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, method, warpMax, profile, subsequence)\n",
            "    return"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [],
         "source": [
            "def multiple_benchmark(settings, save_times, profile = None):\n",
            "    \"\"\"\n",
            "    Settings is a list of individual system descriptions to be run.\n",
            "        ie. [['train_toy', 'Mazurkas_median_x1.000', 'Mazurkas_median_x1.000', 'DTW1'],\n",
            "             ['train_toy', 'Mazurkas_median_x1.260', 'Mazurkas_median_x1.000', 'DTW1'],...] \n",
            "    \"\"\"\n",
            "    res = []\n",
            "    for setting in settings:\n",
            "        start_time = time.time()\n",
            "        filelist, timing1, timing2, algorithm = setting\n",
            "        single_benchmark(filelist, timing1, timing2, algorithm, profile)\n",
            "        total_time = str(timedelta(seconds=int(time.time() - start_time)))\n",
            "        print(f\"Finished {algorithm} for {filelist} with {timing1} {timing2} in {total_time}\")\n",
            "        res.append(f\"{algorithm},{timing1}{timing2},{total_time}\\n\")\n",
            "    with open(save_times, 'a') as f:\n",
            "        for line in res:\n",
            "            f.write(line)\n",
            "    return"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Run test"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_arguments(filelist, algorithms, subseq=False):\n",
            "    '''create a list of lists to pass into multiple_benchmark based on what alignments we want'''\n",
            "    subseq_str = ''\n",
            "    if subseq:\n",
            "        subseq_str = '_subseq20'\n",
            "    res = []\n",
            "    for algorithm in algorithms:\n",
            "        res += [[filelist, f'x1.000{subseq_str}', 'x1.000', algorithm],\n",
            "                [filelist, f'x1.260{subseq_str}', 'x1.000', algorithm],\n",
            "                [filelist, f'x1.260{subseq_str}', 'x0.794', algorithm],\n",
            "                [filelist, f'x1.588{subseq_str}', 'x0.794', algorithm],\n",
            "                [filelist, f'x1.588{subseq_str}', 'x0.630', algorithm],\n",
            "                [filelist, f'x2.000{subseq_str}', 'x0.630', algorithm],\n",
            "                [filelist, f'x2.000{subseq_str}', 'x0.500', algorithm]]\n",
            "    return res"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Finished DTW1 for train_toy with x1.000 x1.000 in 0:00:04\n",
                  "Finished DTW1 for train_toy with x1.260 x1.000 in 0:00:05\n",
                  "Finished DTW1 for train_toy with x1.260 x0.794 in 0:00:03\n",
                  "Finished DTW1 for train_toy with x1.588 x0.794 in 0:00:05\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW1 for train_toy with x1.588 x0.630 in 0:00:04\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW1 for train_toy with x2.000 x0.630 in 0:00:05\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW1 for train_toy with x2.000 x0.500 in 0:00:03\n",
                  "Finished DTW2 for train_toy with x1.000 x1.000 in 0:00:04\n",
                  "Finished DTW2 for train_toy with x1.260 x1.000 in 0:00:05\n",
                  "Finished DTW2 for train_toy with x1.260 x0.794 in 0:00:04\n",
                  "Finished DTW2 for train_toy with x1.588 x0.794 in 0:00:05\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW2 for train_toy with x1.588 x0.630 in 0:00:04\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW2 for train_toy with x2.000 x0.630 in 0:00:05\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW2 for train_toy with x2.000 x0.500 in 0:00:03\n",
                  "Finished DTW3 for train_toy with x1.000 x1.000 in 0:00:04\n",
                  "Finished DTW3 for train_toy with x1.260 x1.000 in 0:00:05\n",
                  "Finished DTW3 for train_toy with x1.260 x0.794 in 0:00:04\n",
                  "Finished DTW3 for train_toy with x1.588 x0.794 in 0:00:05\n",
                  "Finished DTW3 for train_toy with x1.588 x0.630 in 0:00:04\n",
                  "Finished DTW3 for train_toy with x2.000 x0.630 in 0:00:05\n",
                  "Finished DTW3 for train_toy with x2.000 x0.500 in 0:00:04\n",
                  "Finished DTW4 for train_toy with x1.000 x1.000 in 0:00:04\n",
                  "Finished DTW4 for train_toy with x1.260 x1.000 in 0:00:05\n",
                  "Finished DTW4 for train_toy with x1.260 x0.794 in 0:00:04\n",
                  "Finished DTW4 for train_toy with x1.588 x0.794 in 0:00:05\n",
                  "Finished DTW4 for train_toy with x1.588 x0.630 in 0:00:04\n",
                  "Finished DTW4 for train_toy with x2.000 x0.630 in 0:00:05\n",
                  "Finished DTW4 for train_toy with x2.000 x0.500 in 0:00:04\n",
                  "Finished DTW5 for train_toy with x1.000 x1.000 in 0:00:04\n",
                  "Finished DTW5 for train_toy with x1.260 x1.000 in 0:00:05\n",
                  "Finished DTW5 for train_toy with x1.260 x0.794 in 0:00:04\n",
                  "Finished DTW5 for train_toy with x1.588 x0.794 in 0:00:05\n",
                  "Finished DTW5 for train_toy with x1.588 x0.630 in 0:00:04\n",
                  "Finished DTW5 for train_toy with x2.000 x0.630 in 0:00:05\n",
                  "Finished DTW5 for train_toy with x2.000 x0.500 in 0:00:04\n",
                  "Finished DTW1_add3 for train_toy with x1.000 x1.000 in 0:00:05\n",
                  "Finished DTW1_add3 for train_toy with x1.260 x1.000 in 0:00:06\n",
                  "Finished DTW1_add3 for train_toy with x1.260 x0.794 in 0:00:05\n",
                  "Finished DTW1_add3 for train_toy with x1.588 x0.794 in 0:00:07\n",
                  "Finished DTW1_add3 for train_toy with x1.588 x0.630 in 0:00:05\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW1_add3 for train_toy with x2.000 x0.630 in 0:00:06\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW1_add3 for train_toy with x2.000 x0.500 in 0:00:05\n",
                  "Finished DTW1_add4 for train_toy with x1.000 x1.000 in 0:00:06\n",
                  "Finished DTW1_add4 for train_toy with x1.260 x1.000 in 0:00:08\n",
                  "Finished DTW1_add4 for train_toy with x1.260 x0.794 in 0:00:07\n",
                  "Finished DTW1_add4 for train_toy with x1.588 x0.794 in 0:00:08\n",
                  "Finished DTW1_add4 for train_toy with x1.588 x0.630 in 0:00:06\n",
                  "Finished DTW1_add4 for train_toy with x2.000 x0.630 in 0:00:08\n",
                  "Finished DTW1_add4 for train_toy with x2.000 x0.500 in 0:00:07\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x1.000 x1.000 in 0:00:05\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x1.260 x1.000 in 0:00:05\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x1.260 x0.794 in 0:00:04\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x1.588 x0.794 in 0:00:04\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x1.588 x0.630 in 0:00:04\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x2.000 x0.630 in 0:00:04\n",
                  "Finished DTW1_downsampleQuantized for train_toy with x2.000 x0.500 in 0:00:04\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x1.000 x1.000 in 0:00:07\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x1.260 x1.000 in 0:00:08\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x1.260 x0.794 in 0:00:06\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x1.588 x0.794 in 0:00:06\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x1.588 x0.630 in 0:00:06\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x2.000 x0.630 in 0:00:05\n",
                  "Finished DTW1_downsampleInterpolate for train_toy with x2.000 x0.500 in 0:00:04\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x1.000 x1.000 in 0:00:08\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x1.260 x1.000 in 0:00:11\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x1.260 x0.794 in 0:00:10\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x1.588 x0.794 in 0:00:15\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x1.588 x0.630 in 0:00:15\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x2.000 x0.630 in 0:00:31\n",
                  "Finished DTW1_upsampleQuantized for train_toy with x2.000 x0.500 in 0:00:31\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x1.000 x1.000 in 0:00:10\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x1.260 x1.000 in 0:00:14\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x1.260 x0.794 in 0:00:14\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x1.588 x0.794 in 0:00:18\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x1.588 x0.630 in 0:00:18\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x2.000 x0.630 in 0:00:42\n",
                  "Finished DTW1_upsampleInterpolate for train_toy with x2.000 x0.500 in 0:00:39\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x1.000 x1.000 in 0:00:13\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x1.260 x1.000 in 0:00:13\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x1.260 x0.794 in 0:00:14\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x1.588 x0.794 in 0:00:15\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x1.588 x0.630 in 0:00:14\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x2.000 x0.630 in 0:00:17\n",
                  "Finished DTW_adaptiveWeight1 for train_toy with x2.000 x0.500 in 0:00:16\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x1.000 x1.000 in 0:00:17\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x1.260 x1.000 in 0:00:18\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x1.260 x0.794 in 0:00:17\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x1.588 x0.794 in 0:00:19\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x1.588 x0.630 in 0:00:20\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x2.000 x0.630 in 0:00:21\n",
                  "Finished DTW_adaptiveWeight2 for train_toy with x2.000 x0.500 in 0:00:20\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x1.000 x1.000 in 0:00:24\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x1.260 x1.000 in 0:00:26\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x1.260 x0.794 in 0:00:26\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x1.588 x0.794 in 0:00:28\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x1.588 x0.630 in 0:00:29\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x2.000 x0.630 in 0:00:30\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW_selectiveTransitions2 for train_toy with x2.000 x0.500 in 0:00:27\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x1.000 x1.000 in 0:00:27\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x1.260 x1.000 in 0:00:31\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x1.260 x0.794 in 0:00:30\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x1.588 x0.794 in 0:00:33\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x1.588 x0.630 in 0:00:30\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x2.000 x0.630 in 0:00:32\n",
                  "A path is not possible\n",
                  "A path is not possibleA path is not possible\n",
                  "\n",
                  "A path is not possible\n",
                  "A path is not possible\n",
                  "Finished DTW_selectiveTransitions3 for train_toy with x2.000 x0.500 in 0:00:33\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x1.000 x1.000 in 0:00:37\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x1.260 x1.000 in 0:00:38\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x1.260 x0.794 in 0:00:36\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x1.588 x0.794 in 0:00:40\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x1.588 x0.630 in 0:00:37\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x2.000 x0.630 in 0:00:39\n",
                  "Finished DTW_selectiveTransitions4 for train_toy with x2.000 x0.500 in 0:00:36\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x1.000 x1.000 in 0:00:34\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x1.260 x1.000 in 0:00:44\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x1.260 x0.794 in 0:00:36\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x1.588 x0.794 in 0:01:10\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x1.588 x0.630 in 0:00:38\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x2.000 x0.630 in 0:00:56\n",
                  "Finished DTW_selectiveTransitions5 for train_toy with x2.000 x0.500 in 0:00:43\n"
               ]
            }
         ],
         "source": [
            "args = get_arguments('train_medium', ['DTW1', 'DTW2', 'DTW3', 'DTW4', 'DTW5', 'DTW1_add3', 'DTW1_add4', 'DTW1_downsampleQuantized', 'DTW1_downsampleInterpolate', 'DTW1_upsampleQuantized', 'DTW1_upsampleInterpolate', 'DTW_adaptiveWeight1', 'DTW_adaptiveWeight2', 'DTW_selectiveTransitions2','DTW_selectiveTransitions3','DTW_selectiveTransitions4','DTW_selectiveTransitions5'])\n",
            "multiple_benchmark(args, save_times='train_medium_times.txt')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.7.7"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
