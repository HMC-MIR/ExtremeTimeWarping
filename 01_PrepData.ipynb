{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prep the data for the alignment task.  This includes computing audio features and generating a query list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('Chopin_Mazurkas/annotations_beat')\n",
    "AUDIO_ROOT = Path('Chopin_Mazurkas/wav_22050_mono')\n",
    "FEATURES_ROOT = Path('features')\n",
    "train_files = Path('cfg_files/filelist.train.txt')\n",
    "test_files = Path('cfg_files/filelist.test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FEATURES_ROOT):\n",
    "    os.mkdir(FEATURES_ROOT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create filelists text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(piece, filelist, seed=42):\n",
    "    \"\"\"\n",
    "    For a given piece (ie. Chopin_Op017No4), return a list\n",
    "    of tuples of all pair wise combinations between performances.\n",
    "    \"\"\"\n",
    "    performances = []\n",
    "    with open(filelist, 'r') as infile:\n",
    "        for performance in infile:\n",
    "            if piece in performance:\n",
    "                performances.append(performance.split())\n",
    "    pairs = list(combinations(performances, 2))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(pairs)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = get_combinations('Chopin_Op017No4', train_files) + get_combinations('Chopin_Op063No3', train_files)\n",
    "test_pairs = get_combinations('Chopin_Op024No2', test_files) + get_combinations('Chopin_Op030No2', test_files) + get_combinations('Chopin_Op068No3', test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(pairs, outdir, limit=None):\n",
    "    \"\"\" Save pairs to filelist.*.txt file \"\"\"\n",
    "    if limit:\n",
    "        pairs = pairs[:limit]\n",
    "    with open(outdir, 'w') as outfile:\n",
    "        for a, b in pairs:\n",
    "            outfile.write(f\"{a[0]} {b[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-toy: randomly select 5 pairs from Op 17 #4\n",
    "create_file_list(train_pairs, 'cfg_files/filelist.train_toy.txt', 5)\n",
    "# train-small: randomly select 200 pairs from Op 17 #4\n",
    "create_file_list(train_pairs, 'cfg_files/filelist.train_small.txt', 200)\n",
    "# train-medium: includes all (63 choose 2) pairs for Op 17 #4\n",
    "create_file_list(train_pairs, 'cfg_files/filelist.train_medium.txt', 1953)\n",
    "# train-full: includes all (63 choose 2) + (88, choose 2) pairs for Op 17 #4 and Op 63 #3\n",
    "create_file_list(train_pairs, 'cfg_files/filelist.train_full.txt')\n",
    "# test-full: includes all pairs from the 3 test Mazurkas\n",
    "create_file_list(test_pairs, 'cfg_files/filelist.test_full.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find median duration for each piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median():\n",
    "    medians = {}\n",
    "    dirs = glob.glob('Chopin_Mazurkas/wav_22050_mono/*/**/', recursive=True)\n",
    "    for dir in dirs:\n",
    "        piece = os.path.split(os.path.normpath(dir))[-1]\n",
    "        performances = glob.glob(f'{dir}*.wav', recursive=True)\n",
    "        durations = [lb.get_duration(filename=path) for path in performances]\n",
    "        durations.sort()\n",
    "        medians[piece] = durations[len(durations)//2]\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = get_median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.92816326530613\n",
      "128.22149659863945\n",
      "136.6748299319728\n",
      "87.30149659863946\n",
      "98.16816326530612\n"
     ]
    }
   ],
   "source": [
    "Chopin_Op017No4_MEDIAN = medians['Chopin_Op017No4']\n",
    "Chopin_Op063No3_MEDIAN = medians['Chopin_Op063No3']\n",
    "Chopin_Op024No2_MEDIAN = medians['Chopin_Op024No2']\n",
    "Chopin_Op030No2_MEDIAN = medians['Chopin_Op030No2']\n",
    "Chopin_Op068No3_MEDIAN = medians['Chopin_Op068No3']\n",
    "print(Chopin_Op017No4_MEDIAN)\n",
    "print(Chopin_Op063No3_MEDIAN)\n",
    "print(Chopin_Op024No2_MEDIAN)\n",
    "print(Chopin_Op030No2_MEDIAN)\n",
    "print(Chopin_Op068No3_MEDIAN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct modified benchmark datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create separate directories for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mazurka_directories(time_modify):\n",
    "    '''create separate directories for each time scale modification'''\n",
    "    for item in time_modify:\n",
    "        dir = 'Mazurkas_median_x{}'.format(item)\n",
    "        ann_dir = '{}/annotations_beat'.format(dir)\n",
    "        wav_dir = '{}/wav_22050_mono'.format(dir)\n",
    "        for mazurka in ['Chopin_Op017No4','Chopin_Op024No2','Chopin_Op030No2','Chopin_Op063No3','Chopin_Op068No3']:\n",
    "            ann_piece_dir = '{}/{}'.format(ann_dir, mazurka)\n",
    "            wav_piece_dir = '{}/{}'.format(wav_dir, mazurka)\n",
    "            if not os.path.exists(ann_piece_dir):\n",
    "                os.makedirs(ann_piece_dir)\n",
    "            if not os.path.exists(wav_piece_dir):\n",
    "                os.makedirs(wav_piece_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['1.000','0.500','0.630','0.794','1.260','1.588','2.000']\n",
    "create_mazurka_directories(factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform time-scale modification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "from tsm_tools import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_batch(filelist, piece, median_duration, factor, outdir, n_cores):\n",
    "    '''time-scale modify for all .wav files for one mazurka for one factor'''\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as cfg_file:\n",
    "        for line in cfg_file:\n",
    "            if piece in line:\n",
    "                # make path to .wav file\n",
    "                path_to_wav = 'Chopin_Mazurkas/wav_22050_mono/{}.wav'.format(line[:-1])\n",
    "                inputs.append((path_to_wav, median_duration, factor, outdir))\n",
    "    \n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(time_scale_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_single(path_to_wav, median_duration, factor, outdir):\n",
    "    '''time-scale modify for one .wav file'''\n",
    "    y, sr = lb.load(path_to_wav)\n",
    "    # do time scale modification\n",
    "    old_duration = lb.get_duration(y=y, sr=sr)\n",
    "    ratio = (median_duration*factor) / old_duration\n",
    "    y_mod = tsm_hybrid(y, alpha=ratio)\n",
    "    # save to new .wav file\n",
    "    new_path_to_wav = '{}{}'.format(outdir, path_to_wav[15:]) # e.g. 'Mazurkas_median_x1.000/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Kitain-1937_pid9163-02.wav'\n",
    "    #lb.output.write_wav(new_path_to_wav, y, sr)\n",
    "    sf.write(new_path_to_wav, y_mod, sr)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_by_mazurka(filelist, piece, median_duration, factors):\n",
    "    '''time-scale modify by all factors with one mazurka'''\n",
    "    for factor in factors:\n",
    "        time_scale_batch(filelist, piece, median_duration, float(factor),'Mazurkas_median_x{}'.format(factor), 24)\n",
    "        print(\"Done with Mazurkas_median_x{}/{}\".format(factor, piece))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(train_files,'Chopin_Op017No4',Chopin_Op017No4_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(train_files,'Chopin_Op063No3',Chopin_Op063No3_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(test_files,'Chopin_Op024No2',Chopin_Op024No2_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(test_files,'Chopin_Op030No2',Chopin_Op030No2_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(test_files,'Chopin_Op068No3',Chopin_Op068No3_MEDIAN,factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate .beat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestamps(annotfile):\n",
    "    df = pd.read_csv(annotfile, header=None, sep='\\s+', skiprows=3)\n",
    "    return np.array(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beat_annotation(in_path_beat, in_path_wav, out_path, num_multiply): # num_multiply should be median*factor\n",
    "    '''modifies beat annotations for one .wav file'''\n",
    "    # load .wav file to get original duration\n",
    "    real_duration = lb.get_duration(filename=in_path_wav)\n",
    "    # (median*factor)/real_dur\n",
    "    original_ts = getTimestamps(in_path_beat)\n",
    "    modified_ts = (original_ts*num_multiply)/real_duration\n",
    "    index = 0\n",
    "    curr_read = 0\n",
    "    new_lines = []\n",
    "    with open(in_path_beat, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if curr_read < 3: # copy first 3 lines\n",
    "                new_lines.append(line)\n",
    "                curr_read += 1\n",
    "                continue\n",
    "            else: # modify the rest of the lines\n",
    "                label = line.split('\\t')[-1]\n",
    "                if index+1 == len(modified_ts):\n",
    "                    curr_start, curr_end = modified_ts[index], 0.0\n",
    "                else:\n",
    "                    curr_start, curr_end = modified_ts[index], modified_ts[index+1]\n",
    "                new_string = '{}\\t{}\\t{}'.format(curr_start, curr_end, label)\n",
    "                new_lines.append(new_string)\n",
    "                index += 1\n",
    "    with open(out_path, 'w') as outfile:\n",
    "        for line in new_lines:\n",
    "            outfile.write(line)\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_beat_annotation('Chopin_Mazurkas/annotations_beat/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.beat', 'Chopin_Mazurkas/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.wav', 'test.beat', Chopin_Op017No4_MEDIAN*2)[3:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beat_annotation_batch(filelist, piece, median_duration, factor, outdir, n_cores): # e.g. outdir is 'Mazurkas_median_x2.000/annotations_beat/Chopin_Op017No4'\n",
    "    '''modifies beat annotations for all .wav files for one Mazurka for one factor'''\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as cfg_file:\n",
    "        for line in cfg_file:\n",
    "            if piece in line:\n",
    "                path_to_beat = 'Chopin_Mazurkas/annotations_beat/{}.beat'.format(line[:-1])\n",
    "                path_to_wav = 'Chopin_Mazurkas/wav_22050_mono/{}.wav'.format(line[:-1])\n",
    "                out_path = 'Mazurkas_median_x{}/annotations_beat/{}.beat'.format(factor, line[:-1])\n",
    "                num_multiply = median_duration*float(factor)\n",
    "                inputs.append((path_to_beat, path_to_wav, out_path, num_multiply))\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(create_beat_annotation, inputs)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_beat_annotation_batch(train_files, 'Chopin_Op017No4', Chopin_Op017No4_MEDIAN, '2.000', 'Mazurkas_median_x2.000/annotations_beat/Chopin_Op017No4', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_annotation_by_mazurka(filelist, piece, median_duration, factors):\n",
    "    '''modifies beat annotations by all factors with one mazurka'''\n",
    "    for factor in factors:\n",
    "        create_beat_annotation_batch(filelist, piece, median_duration, factor, 'Mazurkas_median_x{}/annotations_beat/{}'.format(factor, piece), 24)\n",
    "        print(\"Done with Mazurkas_median_x{}/annotations_beat/{}\".format(factor, piece))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_annotation_by_mazurka(train_files, 'Chopin_Op017No4', Chopin_Op017No4_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(train_files, 'Chopin_Op063No3', Chopin_Op063No3_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(test_files, 'Chopin_Op024No2', Chopin_Op024No2_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(test_files, 'Chopin_Op030No2', Chopin_Op030No2_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(test_files, 'Chopin_Op068No3', Chopin_Op068No3_MEDIAN, factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features on clean audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute features on the audio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute features on the 'Chopin_Mazurkas' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_single(infile, outfile, sr = 22050, hop_length=512):\n",
    "    y, sr = lb.core.load(infile, sr = sr)\n",
    "    #F = lb.feature.chroma_cens(y, sr=sr, hop_length=hop_length)\n",
    "    F = lb.feature.chroma_cqt(y, sr=sr, hop_length=hop_length, norm=2)\n",
    "    np.save(outfile, F)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_batch(filelist, outdir, n_cores):\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = outdir / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = (AUDIO_ROOT / relpath).with_suffix('.wav')\n",
    "            if os.path.exists(featfile):\n",
    "                print(f\"Skipping {featfile}\")\n",
    "            else:\n",
    "                inputs.append((audiofile, featfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(compute_chroma_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_CLEAN_DIR = FEATURES_ROOT / 'clean'\n",
    "compute_chroma_batch(train_files, FEATS_CLEAN_DIR, 24)\n",
    "compute_chroma_batch(test_files, FEATS_CLEAN_DIR, 24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute features on the modified median directories e.g. 'Mazurkas_median_x0.500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_median(filelist, median_dir, outdir, n_cores): # outdir should be 'features/clean'\n",
    "    '''compute features for each median directory e.g. for all .wav files in 'Mazurkas_median_x0.500' '''\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = median_dir / outdir / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = (median_dir / Path('wav_22050_mono') / relpath).with_suffix('.wav')\n",
    "            if os.path.exists(featfile):\n",
    "                print(f\"Skipping {featfile}\")\n",
    "            else:\n",
    "                inputs.append((audiofile, featfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(compute_chroma_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_CLEAN_DIR = FEATURES_ROOT / 'clean'\n",
    "median_directories = ['Mazurkas_median_x0.500', 'Mazurkas_median_x0.630', 'Mazurkas_median_x0.794', 'Mazurkas_median_x1.000', 'Mazurkas_median_x1.260', 'Mazurkas_median_x1.588', 'Mazurkas_median_x2.000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute chromas for each directory\n",
    "for median_dir in median_directories:\n",
    "    compute_chroma_median(train_files, median_dir, FEATS_CLEAN_DIR, 24)\n",
    "    compute_chroma_median(test_files, median_dir, FEATS_CLEAN_DIR, 24)\n",
    "    print(\"Finished generating features for {}\".format(median_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more than 100 milliseconds. if its 1 milliseconds it should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All recordings in Chopin_Op063No3 (x0.63) within range\n",
      "All recordings in Chopin_Op017No4 (x0.63) within range\n",
      "All recordings in Chopin_Op030No2 (x0.63) within range\n",
      "All recordings in Chopin_Op024No2 (x0.63) within range\n",
      "All recordings in Chopin_Op068No3 (x0.63) within range\n",
      "All recordings in Chopin_Op063No3 (x2.0) within range\n",
      "All recordings in Chopin_Op017No4 (x2.0) within range\n",
      "All recordings in Chopin_Op030No2 (x2.0) within range\n",
      "All recordings in Chopin_Op024No2 (x2.0) within range\n",
      "All recordings in Chopin_Op068No3 (x2.0) within range\n",
      "All recordings in Chopin_Op063No3 (x1.26) within range\n",
      "All recordings in Chopin_Op017No4 (x1.26) within range\n",
      "All recordings in Chopin_Op030No2 (x1.26) within range\n",
      "All recordings in Chopin_Op024No2 (x1.26) within range\n",
      "All recordings in Chopin_Op068No3 (x1.26) within range\n",
      "All recordings in Chopin_Op063No3 (x0.5) within range\n",
      "All recordings in Chopin_Op017No4 (x0.5) within range\n",
      "All recordings in Chopin_Op030No2 (x0.5) within range\n",
      "All recordings in Chopin_Op024No2 (x0.5) within range\n",
      "All recordings in Chopin_Op068No3 (x0.5) within range\n",
      "All recordings in Chopin_Op063No3 (x1.0) within range\n",
      "All recordings in Chopin_Op017No4 (x1.0) within range\n",
      "All recordings in Chopin_Op030No2 (x1.0) within range\n",
      "All recordings in Chopin_Op024No2 (x1.0) within range\n",
      "All recordings in Chopin_Op068No3 (x1.0) within range\n",
      "All recordings in Chopin_Op063No3 (x1.588) within range\n",
      "All recordings in Chopin_Op017No4 (x1.588) within range\n",
      "All recordings in Chopin_Op030No2 (x1.588) within range\n",
      "All recordings in Chopin_Op024No2 (x1.588) within range\n",
      "All recordings in Chopin_Op068No3 (x1.588) within range\n",
      "All recordings in Chopin_Op063No3 (x0.794) within range\n",
      "All recordings in Chopin_Op017No4 (x0.794) within range\n",
      "All recordings in Chopin_Op030No2 (x0.794) within range\n",
      "All recordings in Chopin_Op024No2 (x0.794) within range\n",
      "All recordings in Chopin_Op068No3 (x0.794) within range\n"
     ]
    }
   ],
   "source": [
    "def verify_benchmark_durations(medians, tolerance = 1e-2):\n",
    "    dirs = glob.glob('Mazurkas_median_*')\n",
    "    for dir in dirs:\n",
    "        pieces = glob.glob(f'{dir}/wav_22050_mono/*/**/', recursive=True)\n",
    "        for piece in pieces:\n",
    "            factor, pieceid = os.path.split(os.path.normpath(piece))\n",
    "            factor = float(os.path.split(factor)[0].split('_x')[1])\n",
    "            recordings = glob.glob(f\"{piece}/*\")\n",
    "            for recording in recordings:\n",
    "                duration = lb.get_duration(filename=recording)\n",
    "                assert duration >= (medians[pieceid] * factor * (1 - tolerance))\n",
    "                assert duration <= (medians[pieceid] * factor * (1 + tolerance))\n",
    "            print(f'All recordings in {pieceid} (x{factor}) within range')\n",
    "\n",
    "verify_benchmark_durations(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_beat_annotation('Chopin_Mazurkas/annotations_beat/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.beat', 'Chopin_Mazurkas/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.wav', 'test.beat', Chopin_Op017No4_MEDIAN*2)[3:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_duration = lb.get_duration(filename=\"Chopin_Mazurkas/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.wav\")\n",
    "factor = Chopin_Op017No4_MEDIAN * 2 / real_duration\n",
    "curr_read = 0\n",
    "lines = []\n",
    "with open('Chopin_Mazurkas/annotations_beat/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.beat', 'r') as infile:\n",
    "    for line in infile:\n",
    "        if curr_read < 3:\n",
    "            curr_read += 1\n",
    "            continue\n",
    "        start, end, label = line.split('\\t')\n",
    "        start = factor * float(start)\n",
    "        end = factor * float(end)\n",
    "        lines.append(f\"{start}\\t{end}\\t{label}\")\n",
    "        curr_read += 1\n",
    "        if curr_read >= 8:\n",
    "            break\n",
    "lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
