{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('Chopin_Mazurkas/annotations_beat')\n",
    "query_list = Path('cfg_files/query.test.list')\n",
    "\n",
    "# For modified files\n",
    "query_list_train_toy = Path('cfg_files/filelist.train_toy.txt')\n",
    "query_list_train_small = Path('cfg_files/filelist.train_small.txt')\n",
    "query_list_train_medium = Path('cfg_files/filelist.train_medium.txt')\n",
    "query_list_train_full = Path('cfg_files/filelist.train_full.txt')\n",
    "query_list_test_full = Path('cfg_files/filelist.test_full.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate hypothesis directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First evaluate a single hypothesis directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dir(hypdir, querylist, hop_sec, annotation_root1, annotation_root2, savefile = None):\n",
    "    allErrs = {}\n",
    "    cnt = 0\n",
    "    print(f'Processing {hypdir} ', end='')\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            assert len(parts) == 2\n",
    "            basename = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            hypfile = hypdir + '/' + basename + '.pkl'\n",
    "            if not os.path.exists(hypfile):\n",
    "                print(\"X\", end='')\n",
    "                continue\n",
    "            allErrs[basename] = eval_file(hypfile, hop_sec, annotation_root1, annotation_root2)\n",
    "            cnt += 1\n",
    "            if cnt % 500 == 0:\n",
    "                print(\".\", end='')\n",
    "    print(' done')\n",
    "    if savefile:\n",
    "        pickle.dump(allErrs, open(savefile, 'wb'))\n",
    "        \n",
    "    return allErrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_file(hypfile, hop_sec, annotation_root1, annotation_root2):\n",
    "    parts = os.path.basename(hypfile).split('__')\n",
    "    assert len(parts) == 2\n",
    "    piece = extractPieceName(parts[0])\n",
    "    annotfile1 = (Path(annotation_root1) / piece / parts[0]).with_suffix('.beat')\n",
    "    annotfile2 = (Path(annotation_root2) / piece / parts[1]).with_suffix('.beat')\n",
    "    gt1 = getTimestamps(annotfile1)\n",
    "    gt2 = getTimestamps(annotfile2)\n",
    "    hypalign = loadAlignment(hypfile) # warping path in frames\n",
    "    if hypalign is None:\n",
    "        err = [] # no valid path\n",
    "    else:\n",
    "        pred2 = np.interp(gt1, hypalign[0,:]*hop_sec, hypalign[1,:]*hop_sec)\n",
    "        err = pred2 - gt2\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPieceName(fullpath):\n",
    "    basename = os.path.basename(fullpath) # e.g. Chopin_Op068No3_Sztompka-1959_pid9170b-21\n",
    "    parts = basename.split('_')\n",
    "    piece = '_'.join(parts[0:2]) # e.g. Chopin_Op068No3\n",
    "    return piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestamps(annotfile):\n",
    "    df = pd.read_csv(annotfile, header=None, sep='\\s+', skiprows=3)\n",
    "    return np.array(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAlignment(hypfile):\n",
    "    with open(hypfile, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    return d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate a single hypothesis directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiments_test/test_full...DTW1 ....... done\n"
     ]
    }
   ],
   "source": [
    "# hypdir = 'experiments_test/test_full...DTW1'\n",
    "# savefile = 'evaluations_test/test_full...DTW1.pkl'\n",
    "# hop_sec = 512 * 1 / 22050\n",
    "# allErrs = eval_dir(hypdir, query_list_test_full, hop_sec, ANNOTATIONS_ROOT, ANNOTATIONS_ROOT, savefile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all hypothesis directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_dirs(rootdir, querylist, hop_sec, outdir):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    reldir = str(querylist).split('.')[1]\n",
    "    for hypdir in glob.glob(f'{rootdir}/{reldir}*'): # NOT SURE IF THIS WORKS\n",
    "        savefile = outdir + '/' + os.path.basename(hypdir) + '.pkl'\n",
    "        # get annotation_root1, annotation_root2\n",
    "        info = hypdir.split('.')\n",
    "        annotation_root1 = 'Mazurkas_median_{}.{}/annotations_beat'.format(info[1][:2], info[1][2:])\n",
    "        annotation_root2 = 'Mazurkas_median_{}.{}/annotations_beat'.format(info[2][:2], info[2][2:])\n",
    "        allErrs = eval_dir(hypdir, querylist, hop_sec, annotation_root1, annotation_root2, savefile = savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiments_test/train_toy.x1588.x0630.DTW1  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW2  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW3  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW1_upsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW1  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW2  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW2  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW1_upsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW3  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW3  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW1  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW1_upsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW1  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW3  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW3  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW1  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW2  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW3  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW3  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW2  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW1_upsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1000.x1000.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW2  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW1_upsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW_adaptiveWeight1  done\n",
      "Processing experiments_test/train_toy.x1260.x0794.DTW1_upsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1588.x0794.DTW_adaptiveWeight2  done\n",
      "Processing experiments_test/train_toy.x1588.x0630.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW1  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW1_downsampleQuantized  done\n",
      "Processing experiments_test/train_toy.x2000.x0500.DTW2  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW1_upsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW1  done\n",
      "Processing experiments_test/train_toy.x1260.x1000.DTW1_downsampleInterpolate  done\n",
      "Processing experiments_test/train_toy.x2000.x0630.DTW1_upsampleInterpolate  done\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENTS_ROOT = 'experiments_test'\n",
    "hop_sec = 512 * 1 / 22050\n",
    "outdir = 'evaluations_test'\n",
    "eval_all_dirs(EXPERIMENTS_ROOT, query_list_train_toy, hop_sec, outdir) # evaluate all directories with train_toy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot error vs tolerance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_time_warp(num1, num2):\n",
    "    ''' calculate global time warp from two numbers'''\n",
    "    return round(num1/num2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_basename(dir):\n",
    "    '''get system, global_time_warp from basename (name of a folder)'''\n",
    "    info = dir.split('.')\n",
    "    system = info[3]\n",
    "    num1 = float('{}.{}'.format(info[1][1], info[1][2:]))\n",
    "    num2 = float('{}.{}'.format(info[2][1], info[2][2:]))\n",
    "    global_time_warp = get_global_time_warp(num1, num2)\n",
    "    return system, global_time_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_names(filelist, alignments_list):\n",
    "    '''create a list of lists of folder names corresponding to filelist and alignment types'''\n",
    "    all_folders = []\n",
    "    for alignment in alignments_list:\n",
    "        to_concat = ['{}.x1000.x1000.{}'.format(filelist, alignment), '{}.x1260.x0794.{}'.format(filelist, alignment), '{}.x1260.x1000.{}'.format(filelist, alignment),\n",
    "                     '{}.x1588.x0630.{}'.format(filelist, alignment), '{}.x1588.x0794.{}'.format(filelist, alignment),\n",
    "                     '{}.x2000.x0630.{}'.format(filelist, alignment), '{}.x2000.x0500.{}'.format(filelist, alignment)]\n",
    "        \n",
    "        all_folders = all_folders + to_concat\n",
    "    return all_folders\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_rates(errFile, maxTol):\n",
    "    # read from file\n",
    "    with open(errFile, 'rb') as f:\n",
    "        allErrs = pickle.load(f)\n",
    "    \n",
    "    # collect all errors\n",
    "    errsFlat = []\n",
    "    for query in allErrs:\n",
    "        errs = np.array(allErrs[query])\n",
    "        errsFlat.append(errs)\n",
    "    errsFlat = np.concatenate(errsFlat)\n",
    "    \n",
    "    # calculate error rates\n",
    "    errRates = np.zeros(maxTol+1)\n",
    "    for i in range(maxTol+1):\n",
    "        errRates[i] = np.mean(np.abs(errsFlat) > i/1000)\n",
    "    \n",
    "    return errRates, errsFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_rates_batch(indir, basenames, maxTol):\n",
    "    errRates = np.zeros((len(basenames), maxTol+1))\n",
    "    allErrVals = []\n",
    "    print('Computing error rates ', end='')\n",
    "    for i, basename in enumerate(basenames):\n",
    "        errFile = indir + '/' + basename + '.pkl'\n",
    "        errRates[i,:], errors = calc_error_rates(errFile, maxTol)\n",
    "        allErrVals.append(errors)\n",
    "        print('.', end='')\n",
    "    print(' done')\n",
    "    return errRates, allErrVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_roc(errRates, basenames):\n",
    "    numSystems = errRates.shape[0]\n",
    "    maxTol = errRates.shape[1] - 1\n",
    "    for i in range(numSystems):\n",
    "        plt.plot(np.arange(maxTol+1), errRates[i,:] * 100.0)\n",
    "        \n",
    "    # create appropriate legend names corresponding to basenames\n",
    "    legend = []\n",
    "    for folder in basenames:\n",
    "        system, global_time_warp = get_info_from_basename(folder)\n",
    "        legend.append('Global Time Warp = {}, {}'.format(global_time_warp, system))\n",
    "    \n",
    "    plt.legend(legend, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    plt.xlabel('Error Tolerance (ms)')\n",
    "    plt.ylabel('Error Rate (%)')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the 'toPlot' list to include only the alignment algorithms we've run so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing error rates ............................................................................. done\n"
     ]
    }
   ],
   "source": [
    "EVAL_ROOT_DIR = 'evaluations_test'\n",
    "toPlot = get_folder_names('train_toy', ['DTW1', 'DTW2', 'DTW3', 'DTW1_add3', 'DTW1_add4', 'DTW1_downsampleQuantized','DTW1_downsampleInterpolate','DTW1_upsampleQuantized','DTW1_upsampleInterpolate', 'DTW_adaptiveWeight1', 'DTW_adaptiveWeight2'])\n",
    "maxTol = 1000 # in msec\n",
    "errRates, errVals = calc_error_rates_batch(EVAL_ROOT_DIR, toPlot, maxTol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_roc(errRates, toPlot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped barplot: 7 groups corresponding to 7 different global time warp factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(errRates, basenames, tols):\n",
    "    '''generates df to use with histogram'''\n",
    "    data = []\n",
    "    for i, dir in enumerate(basenames):\n",
    "        # get system from basename\n",
    "        system, global_time_warp = get_info_from_basename(dir)\n",
    "        # for tol in tols:\n",
    "        for tol in tols:\n",
    "            # get errors and append\n",
    "            data.append((system, tol, errRates[i,tol]*100, global_time_warp))\n",
    "    df = pd.DataFrame(data, columns = ['System', 'Tolerance', 'Error', 'Global Time Warp'])\n",
    "\n",
    "    # check for NaN which indicates a false path and set error to 100\n",
    "    #df.fillna(100, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_histogram1(df):  \n",
    "    plt.figure(figsize=(10,10))\n",
    "    # Histogram grouped by tolerance\n",
    "    tol_200 = df[df['Tolerance']==200]\n",
    "    tol_500 = df[df['Tolerance']==500]\n",
    "    tol_100 = df[df['Tolerance']==100]\n",
    "    # graph100 = sns.barplot(data=tol_100, x=\"Global Time Warp\", y=\"Error\", hue=\"System\", edgecolor=\"black\", linewidth=1)\n",
    "    graph200 = sns.barplot(data=tol_500, x=\"Global Time Warp\", y=\"Error\", hue=\"System\", palette=\"rocket\")\n",
    "    # graph500 = sns.barplot(data=tol_500, x=\"Global Time Warp\", y=\"Error\", hue=\"System\", edgecolor=\"black\", linewidth=1)\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"Global Time Warp\", size=16)\n",
    "    plt.ylabel(\"Error Rate\", size=16)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8ea0e859c959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrRates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoPlot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_df' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = generate_df(errRates, toPlot, [200, 500, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5e0060eaac12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_grouped_histogram1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "plot_grouped_histogram1(df1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_histogram1(errRates_bars, errRates_dots, basenames, tols, savefile = None):  \n",
    "    # Histogram grouped by tolerance\n",
    "    \n",
    "    # first construct DataFrame\n",
    "    data = []\n",
    "    for i, system in enumerate(basenames):\n",
    "        for tol in tols:\n",
    "            data.append((system, tol, errRates[i,tol] * 100.0))\n",
    "    df = pd.DataFrame(data, columns = ['System', 'Tolerance', 'Error'])\n",
    "    \n",
    "    # grouped barplot (DTW & WSDTW)\n",
    "    sns.barplot(x=\"Tolerance\", y=\"Error\", hue=\"System\", data=df)\n",
    "    plt.xlabel(\"Tolerance (ms)\", size=14)\n",
    "    plt.ylabel(\"Error Rate (%)\", size=14)\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # overlay dots for SSDTW results\n",
    "    width_bar = .135\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "    for i, tol in enumerate(tols):\n",
    "        for j in range(errRates_dots.shape[0]):\n",
    "            x_coords.append(i+(-1.5+j)*width_bar)\n",
    "            y_coords.append(errRates_dots[j,tol] * 100.0)\n",
    "    plt.plot(x_coords, y_coords, 'ko', markersize=3)\n",
    "    \n",
    "    if savefile:\n",
    "        plt.savefig(savefile, bbox_inches = 'tight')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTW</td>\n",
       "      <td>10</td>\n",
       "      <td>74.655177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTW</td>\n",
       "      <td>20</td>\n",
       "      <td>55.672810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTW</td>\n",
       "      <td>50</td>\n",
       "      <td>29.834394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTW</td>\n",
       "      <td>100</td>\n",
       "      <td>17.209739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTW</td>\n",
       "      <td>200</td>\n",
       "      <td>8.536578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTW</td>\n",
       "      <td>500</td>\n",
       "      <td>3.399190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  System  Tolerance      Error\n",
       "0    DTW         10  74.655177\n",
       "1    DTW         20  55.672810\n",
       "2    DTW         50  29.834394\n",
       "3    DTW        100  17.209739\n",
       "4    DTW        200   8.536578\n",
       "5    DTW        500   3.399190"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tols = [10, 20, 50, 100, 200, 500] # in msec\n",
    "display_names = ['DTW']#, 'SegDTW-2', 'SegDTW-4', 'SegDTW-8', 'SegDTW-16','SegDTW-32']\n",
    "savefile = 'results.png'\n",
    "plot_grouped_histogram1(errRates[0:6,:], errRates[6:,:], display_names, tols, savefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
