{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment code DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lb\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "DTYPE_INT32 = np.int32\n",
    "ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "DTYPE_FLOAT = np.float64\n",
    "ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_Cost_To_AccumCostAndSteps(Cin, parameter):\n",
    "    '''\n",
    "    Inputs\n",
    "        C: The cost Matrix\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    Section for checking and catching errors in the inputs\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] C\n",
    "    try:\n",
    "        C = np.array(Cin, dtype=DTYPE_FLOAT)\n",
    "    except TypeError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the cost matrix is wrong - please pass in a 2-d numpy array\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "    except ValueError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the elements in the cost matrix is wrong - please have each element be a float (perhaps you passed in a matrix of ints?)\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dn\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dm\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=1] dw\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    # dn loading and exception handling\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        try:\n",
    "\n",
    "            dn = np.array(parameter['dn'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dn (row steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"The type of the elements in dn (row steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=np.uint32)\n",
    "    # dm loading and exception handling\n",
    "    if 'dm'  in parameter.keys():\n",
    "        try:\n",
    "            dm = np.array(parameter['dm'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dm (col steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of the elements in dm (col steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        print(bcolors.FAIL + \"dm (col steps) was not passed in (gave default value [1,0,1]) \" + bcolors.ENDC)\n",
    "        dm = np.array([1, 0, 1], dtype=np.uint32)\n",
    "    # dw loading and exception handling\n",
    "    if 'dw'  in parameter.keys():\n",
    "        try:\n",
    "            dw = np.array(parameter['dw'], dtype=DTYPE_FLOAT)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dw (step weights) is wrong - please pass in a 1-d numpy array that holds floats\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE:The type of the elements in dw (step weights) is wrong - please have each element be a float (perhaps you passed ints or a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.float64)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dw = np.array([1, 1, 1], dtype=DTYPE_FLOAT)\n",
    "        print(bcolors.FAIL + \"dw (step weights) was not passed in (gave default value [1,1,1]) \" + bcolors.ENDC)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Section where types are given to the variables we're going to use \n",
    "    '''\n",
    "    # create matrices to store our results (D and E)\n",
    "    cdef DTYPE_INT32_t numRows = C.shape[0] # only works with np arrays, use np.shape(x) will work on lists? want to force to use np though?\n",
    "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
    "    cdef DTYPE_INT32_t numDifSteps = np.size(dw)\n",
    "\n",
    "    cdef unsigned int maxRowStep = max(dn)\n",
    "    cdef unsigned int maxColStep = max(dm)\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] steps = np.zeros((numRows,numCols), dtype=np.uint32)\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((maxRowStep + numRows, maxColStep + numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "    cdef DTYPE_FLOAT_t bestCost\n",
    "    cdef DTYPE_INT32_t bestCostIndex\n",
    "    cdef DTYPE_FLOAT_t costForStep\n",
    "    cdef unsigned int row, col\n",
    "    cdef unsigned int stepIndex\n",
    "\n",
    "    '''\n",
    "    The start of the actual algorithm, now that all our variables are set up\n",
    "    '''\n",
    "    # initializing the cost matrix - depends on whether its subsequence DTW\n",
    "    # essentially allow us to hop on the bottom anywhere (so could start partway through one of the signals)\n",
    "    if parameter['SubSequence']:\n",
    "        for col in range(numCols):\n",
    "            accumCost[maxRowStep, col + maxColStep] = C[0, col]\n",
    "    else:\n",
    "        accumCost[maxRowStep, maxColStep] = C[0,0]\n",
    "\n",
    "    # filling the accumulated cost matrix\n",
    "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
    "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
    "            bestCost = accumCost[<unsigned int>row, <unsigned int>col] # initialize with what's there - so if is an entry point, then can start low\n",
    "            bestCostIndex = 0\n",
    "            # go through each step, find the best one\n",
    "            for stepIndex in range(numDifSteps):\n",
    "                #costForStep = accumCost[<unsigned int>(row - dn[<unsigned int>(stepIndex)]), <unsigned int>(col - dm[<unsigned int>(stepIndex)])] + dw[<unsigned int>(stepIndex)] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                costForStep = accumCost[<unsigned int>((row - dn[(stepIndex)])), <unsigned int>((col - dm[(stepIndex)]))] + dw[stepIndex] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                if costForStep < bestCost:\n",
    "                    bestCost = costForStep\n",
    "                    bestCostIndex = stepIndex\n",
    "            # save the best cost and best cost index\n",
    "            accumCost[row, col] = bestCost\n",
    "            steps[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)] = bestCostIndex\n",
    "\n",
    "    # return the accumulated cost along with the matrix of steps taken to achieve that cost\n",
    "    return [accumCost[maxRowStep:, maxColStep:], steps]\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_GetPath(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
    "    '''\n",
    "\n",
    "    Parameter should have: 'dn', 'dm', 'dw', 'SubSequence'\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dn\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dm\n",
    "    cdef np.uint8_t subseq\n",
    "    cdef np.int32_t startCol # added\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        dn = parameter['dn']\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
    "    if 'dm'  in parameter.keys():\n",
    "        dm = parameter['dm']\n",
    "    else:\n",
    "        dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
    "    if 'SubSequence' in parameter.keys():\n",
    "        subseq = parameter['SubSequence']\n",
    "    else:\n",
    "        subseq = 0\n",
    "    \n",
    "    # added START\n",
    "    if 'startCol' in parameter.keys(): \n",
    "        startCol = parameter['startCol']\n",
    "    else:\n",
    "        startCol = -1\n",
    "    # added END\n",
    "\n",
    "    cdef np.uint32_t numRows\n",
    "    cdef np.uint32_t numCols\n",
    "    cdef np.uint32_t curRow\n",
    "    cdef np.uint32_t curCol\n",
    "    cdef np.uint32_t endCol\n",
    "    cdef DTYPE_FLOAT_t endCost\n",
    "\n",
    "    numRows = accumCost.shape[0]\n",
    "    numCols = accumCost.shape[1]\n",
    "\n",
    "    # either start at the far corner (non sub-sequence)\n",
    "    # or start at the lowest cost entry in the last row (sub-sequence)\n",
    "    # where all of the signal along the row has been used, but only a \n",
    "    # sub-sequence of the signal along the columns has to be used\n",
    "    curRow = numRows - 1\n",
    "    if subseq:\n",
    "        curCol = np.argmin(accumCost[numRows - 1, :])\n",
    "    else:\n",
    "        curCol = numCols - 1\n",
    "        \n",
    "    # added - if specified, overrides above\n",
    "    if startCol >= 0:\n",
    "        curCol = startCol\n",
    "\n",
    "    endCol = curCol\n",
    "    endCost = accumCost[curRow, curCol]\n",
    "\n",
    "    cdef np.uint32_t curRowStep\n",
    "    cdef np.uint32_t curColStep\n",
    "    cdef np.uint32_t curStepIndex\n",
    "\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
    "    path[0, 0] = curRow\n",
    "    path[1, 0] = curCol\n",
    "\n",
    "    cdef np.uint32_t stepsInPath = 1 # starts at one, we add in one before looping\n",
    "    cdef np.uint32_t stepIndex = 0\n",
    "    cdef np.int8_t done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "    while not done:\n",
    "        if accumCost[curRow, curCol] == MAX_FLOAT:\n",
    "            print('A path is not possible')\n",
    "            break\n",
    "\n",
    "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
    "        # or just the bottom (sub-sequence)\n",
    "        # find the step size\n",
    "        curStepIndex = stepsForCost[curRow, curCol]\n",
    "        curRowStep = dn[curStepIndex]\n",
    "        curColStep = dm[curStepIndex]\n",
    "        # backtrack by 1 step\n",
    "        curRow = curRow - curRowStep\n",
    "        curCol = curCol - curColStep\n",
    "        # add your new location onto the path\n",
    "        path[0, stepsInPath] = curRow\n",
    "        path[1, stepsInPath] = curCol\n",
    "        stepsInPath = stepsInPath + 1\n",
    "        # check to see if you're done\n",
    "        done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "\n",
    "    # reverse the path (a matrix with two rows) and return it\n",
    "    return [np.fliplr(path[:, 0:stepsInPath]), endCol, endCost]\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignDTW(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    \n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "    # if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "    #     if outfile:\n",
    "    #         pickle.dump(None, open(outfile, 'wb'))\n",
    "    #     return None\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "    times.append(time.time())\n",
    "\n",
    "    dn = steps[:,0].astype(np.uint32)\n",
    "    dm = steps[:,1].astype(np.uint32)\n",
    "    parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': False}\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters)\n",
    "    times.append(time.time())\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameters)\n",
    "    times.append(time.time())\n",
    "    if outfile:\n",
    "        pickle.dump(wp, open(outfile, 'wb'))\n",
    "    \n",
    "    if profile:\n",
    "        return wp, np.diff(times)\n",
    "    else:\n",
    "        return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, alignment): # alignment is e.g. 'DTW1'\n",
    "    \n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            assert len(parts) == 2\n",
    "            featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "            featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "            queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            outfile = (outdir / queryid).with_suffix('.pkl')\n",
    "            if os.path.exists(outfile):\n",
    "                print(f\"Skipping {outfile}\")\n",
    "            else:\n",
    "                inputs.append((featfile1, featfile2, steps, weights, downsample, outfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(alignment, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other variations of DTW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### downsampling, upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignDTW_sub(F1, F2, downsample, steps, weights, outfile, profile):\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "    times.append(time.time())\n",
    "\n",
    "    dn = steps[:,0].astype(np.uint32)\n",
    "    dm = steps[:,1].astype(np.uint32)\n",
    "    parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': False}\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters)\n",
    "    times.append(time.time())\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameters)\n",
    "    times.append(time.time())\n",
    "    if outfile:\n",
    "        pickle.dump(wp, open(outfile, 'wb'))\n",
    "    \n",
    "    if profile:\n",
    "        return wp, np.diff(times)\n",
    "    else:\n",
    "        return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW1_downsampleQuantized(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    '''need to write a separate function since need to downsample before performing steps in alignDTW'''\n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "\n",
    "    shorter, longer = None, None\n",
    "    \n",
    "    # boolean to keep track of which is F1, F2\n",
    "    F1_long = None\n",
    "    # determine which is longer\n",
    "    if F1.shape[1] >= F2.shape[1]:\n",
    "        longer, shorter = F1, F2\n",
    "        F1_long = True\n",
    "    else:\n",
    "        longer, shorter = F2, F1\n",
    "        F1_long = False\n",
    "\n",
    "    downsampled = np.zeros(shorter.shape)\n",
    "    # determine factor and corresponding indices\n",
    "    factor_down = longer.shape[1]/shorter.shape[1]\n",
    "    idx_down = [round(factor_down*i) for i in range(shorter.shape[1])]\n",
    "\n",
    "    for i in range(shorter.shape[1]): # for each column in new empty array, get corresponding idx to use to select value in longer\n",
    "        idx = idx_down[i]\n",
    "        downsampled[:,i] = longer[:,idx] # copy values over\n",
    "    \n",
    "    # get original variables\n",
    "    if F1_long:\n",
    "        F1 = downsampled\n",
    "    else:\n",
    "        F2 = downsampled\n",
    "\n",
    "    # just same code as alignDTW\n",
    "    return alignDTW_sub(F1, F2, downsample, steps, weights, outfile, profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featfile1 = 'features/clean/Chopin_Op017No4/Chopin_Op017No4_Afanassiev-2001_pid9130-01.npy'\n",
    "# featfile2 = 'features/clean/Chopin_Op017No4/Chopin_Op017No4_Ashkenazy-1981_pid9058-13.npy'\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "\n",
    "# F1, F2, downsampled, idx = DTW1_downsampleQuantized(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW1_downsampleInterpolate(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    '''Same as DTW_downsample_quantized with one difference: rather than assigning the nearest feature vector, handle fractional positions by doing a linear interpolation between the two bordering feature vectors\n",
    "    E.g. if the fractional position is 4.5, then the feature vector will be 0.5*A[:,4] + 0.5*A[:,5]'''\n",
    "    '''E.g. if the fractional position is 4.9, then the feature vector will be 0.1*A[:,4] + 0.9*A[:,5]'''\n",
    "    \n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "\n",
    "    shorter, longer = None, None\n",
    "    \n",
    "    # boolean to keep track of which is F1, F2\n",
    "    F1_long = None\n",
    "    # determine which is longer\n",
    "    if F1.shape[1] >= F2.shape[1]:\n",
    "        longer, shorter = F1, F2\n",
    "        F1_long = True\n",
    "    else:\n",
    "        longer, shorter = F2, F1\n",
    "        F1_long = False\n",
    "\n",
    "    downsampled = np.zeros(shorter.shape)\n",
    "    # determine factor and corresponding indices\n",
    "    factor_down = longer.shape[1]/shorter.shape[1]\n",
    "    idx_down = [factor_down*i for i in range(shorter.shape[1])]\n",
    "\n",
    "    for i in range(shorter.shape[1]): # for each column in new empty array, get corresponding idx to use to select value in longer\n",
    "        idx = idx_down[i]\n",
    "        fraction1 = idx - math.floor(idx) # to use with higher number. e.g. if 1.73, then fraction1 = 0.73\n",
    "        fraction2 = 1 - fraction1\n",
    "        downsampled[:,i] = longer[:,math.floor(idx)]*fraction2 + longer[:,math.ceil(idx)]*fraction1 # copy values over with linear interpolation\n",
    "\n",
    "    # get original variables\n",
    "    if F1_long:\n",
    "        F1 = downsampled\n",
    "    else:\n",
    "        F2 = downsampled\n",
    "\n",
    "    # just same code as alignDTW\n",
    "    return alignDTW_sub(F1, F2, downsample, steps, weights, outfile, profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW1_upsampleQuantized(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    '''Given sequence A and sequence B, upsample the shorter sequence (B) to be the same length as the longer sequence (A)\n",
    "Without loss of generality, assume A is the longer sequence \n",
    "For each position in the upsampled B sequence, assign the nearest feature vector in B (to handle fractional positions)\n",
    "'''\n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "    \n",
    "    shorter, longer = None, None\n",
    "    \n",
    "    # boolean to keep track of which is F1, F2\n",
    "    F1_long = None\n",
    "    # determine which is longer\n",
    "    if F1.shape[1] >= F2.shape[1]:\n",
    "        longer, shorter = F1, F2\n",
    "        F1_long = True\n",
    "    else:\n",
    "        longer, shorter = F2, F1\n",
    "        F1_long = False\n",
    "\n",
    "    upsampled = np.zeros(longer.shape)\n",
    "\n",
    "    # determine factor and corresponding indices\n",
    "    factor_up = shorter.shape[1]/longer.shape[1]\n",
    "    max_idx = shorter.shape[1] - 1\n",
    "    idx_up = [] # want to get indices\n",
    "    for i in range(longer.shape[1]): # for i in range longer\n",
    "        idx = round(factor_up*i)\n",
    "        if idx > max_idx: # need to check that index not out of range\n",
    "            idx -= 1\n",
    "        idx_up.append(idx)\n",
    "\n",
    "    for i in range(longer.shape[1]): # for each column in new empty array, get corresponding idx to use to select value in shorter\n",
    "        idx = idx_up[i]\n",
    "        upsampled[:,i] = shorter[:,idx] # copy values over\n",
    "    \n",
    "\n",
    "    # get original variables\n",
    "    if F1_long:\n",
    "        F2 = upsampled\n",
    "    else:\n",
    "        F1 = upsampled\n",
    "        \n",
    "    \n",
    "    # just same code as alignDTW\n",
    "    return alignDTW_sub(F1, F2, downsample, steps, weights, outfile, profile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW1_upsampleInterpolate(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    '''Same as DTW_upsample_quantized with one difference: rather than assigning the nearest feature vector, handle fractional positions by doing a linear interpolation between the two bordering feature vectors'''\n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "    \n",
    "    shorter, longer = None, None\n",
    "    \n",
    "    # boolean to keep track of which is F1, F2\n",
    "    F1_long = None\n",
    "    # determine which is longer\n",
    "    if F1.shape[1] >= F2.shape[1]:\n",
    "        longer, shorter = F1, F2\n",
    "        F1_long = True\n",
    "    else:\n",
    "        longer, shorter = F2, F1\n",
    "        F1_long = False\n",
    "\n",
    "    upsampled = np.zeros(longer.shape)\n",
    "\n",
    "    # determine factor and corresponding indices\n",
    "    factor_up = shorter.shape[1]/longer.shape[1]\n",
    "    max_idx = shorter.shape[1] - 1\n",
    "    idx_up = [factor_up*i for i in range(longer.shape[1])]\n",
    "\n",
    "    for i in range(longer.shape[1]): # for each column in new empty array, get corresponding idx to use to select value in longer\n",
    "        idx = idx_up[i]\n",
    "        if math.ceil(idx) > max_idx: # check for index out of range\n",
    "            upsampled[:,i] = shorter[:,math.floor(idx)]\n",
    "        else:\n",
    "            fraction1 = idx - math.floor(idx) # to use with higher number. e.g. if 1.73, then fraction1 = 0.73\n",
    "            fraction2 = 1 - fraction1\n",
    "            upsampled[:,i] = shorter[:,math.floor(idx)]*fraction2 + shorter[:,math.ceil(idx)]*fraction1 # copy values over with linear interpolation\n",
    "    \n",
    "    # get original variables\n",
    "    if F1_long:\n",
    "        F2 = upsampled\n",
    "    else:\n",
    "        F1 = upsampled\n",
    "\n",
    "    # just same code as alignDTW\n",
    "    return alignDTW_sub(F1, F2, downsample, steps, weights, outfile, profile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adaptive weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_adaptiveWeight1(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    # calculate weights:\n",
    "    # use alignDTW for the standard DTW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_adaptiveWeight2(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    # calculate weights w1, w2, w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTW_selectiveTransitions(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    '''This is same as DTW except that the set of allowable transitions at each position (i,j) in the pairwise cost matrix may be different\n",
    "Let the max desired time warp factor be WarpMax (an integer)\n",
    "If i%WarpMax == 0, then remove (1,0) transition from that cell\n",
    "If j%WarpMax == 0, then remove (0,1) transition from that cell\n",
    "Otherwise, keep the transitions (0,1), (1,0), (1,1) with weights 1, 1, 2\n",
    "See example figure below for WarpMax = 3\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_DTW_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DTW_settings(alignment):\n",
    "    '''given an alignment type, return steps, weights, alignment_function (function to use given the alignment type specified)'''\n",
    "    n_cores = 1\n",
    "    steps = None\n",
    "    weights = None\n",
    "    downsample = 1\n",
    "    alignment_function = None\n",
    "    if alignment == 'DTW1':\n",
    "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3])\n",
    "        alignment_function = alignDTW\n",
    "    elif alignment == 'DTW2':\n",
    "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        weights = np.array([1,2,2])\n",
    "        alignment_function = alignDTW\n",
    "    elif alignment == 'DTW3':\n",
    "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
    "        weights = np.array([1,1,2])\n",
    "        alignment_function = alignDTW\n",
    "    elif alignment == 'DTW4':\n",
    "        steps = np.array([0,1,1,0,1,1]).reshape((-1,2))\n",
    "        weights = np.array([1,1,1])\n",
    "        alignment_function = alignDTW\n",
    "    elif alignment == 'DTW5':\n",
    "        steps = np.array([0,1,1,0]).reshape((-1,2))\n",
    "        weights = np.array([1,1])\n",
    "        alignment_function = alignDTW\n",
    "\n",
    "    elif alignment == 'DTW1_add3':\n",
    "        steps = np.array([1,1,1,2,2,1,1,3,3,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3,4,4])\n",
    "        alignment_function = alignDTW\n",
    "    elif alignment == 'DTW1_add4':\n",
    "        steps = np.array([1,1,1,2,2,1,1,3,3,1,1,4,4,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3,4,4,5,5])\n",
    "        alignment_function = alignDTW\n",
    "    elif alignment == 'DTW1_downsampleQuantized':\n",
    "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3])\n",
    "        alignment_function = DTW1_downsampleQuantized\n",
    "    elif alignment == 'DTW1_downsampleInterpolate':\n",
    "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3])\n",
    "        alignment_function = DTW1_downsampleInterpolate\n",
    "    elif alignment == 'DTW1_upsampleQuantized':\n",
    "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3])\n",
    "        alignment_function = DTW1_upsampleQuantized\n",
    "    elif alignment == 'DTW1_upsampleInterpolate':\n",
    "        steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        weights = np.array([2,3,3])\n",
    "        alignment_function = DTW1_upsampleInterpolate\n",
    "\n",
    "    return n_cores, steps, weights, downsample, alignment_function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Benchmarks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_benchmark(filelist, folder1, folder2, alignment, outdir='experiments_test'):\n",
    "    # prepare inputs for the align batch function\n",
    "    query_list = 'cfg_files/filelist.{}.txt'.format(filelist) # make 'train_toy' to actual file path --> 'cfg_files/filelist.train_toy.txt'\n",
    "    featdir1 = Path('{}/features/clean'.format(folder1))\n",
    "    featdir2 = Path('{}/features/clean'.format(folder2))\n",
    "    median1 = ''.join(folder1[-6:].split('.')) # make 'Mazurkas_median_x1.000' --> x1000 to simplify out folder name\n",
    "    median2 = ''.join(folder2[-6:].split('.'))\n",
    "    outdir = Path('{}/{}.{}.{}.{}'.format(outdir, filelist, median1, median2, alignment))\n",
    "    \n",
    "    # get alignment settings based on specified alignment type\n",
    "    n_cores, steps, weights, downsample, alignment_function = get_DTW_settings(alignment)\n",
    "\n",
    "    alignDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, alignment_function) # alignDTW_batch works to align all files listed in the filelist\n",
    "    ## add more if statements for each DTW algorithm\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_benchmark('train_toy', 'Mazurkas_median_x1.000', 'Mazurkas_median_x0.794', 'DTW1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_benchmark(settings): # takes in a list of lists. each list inside is a setting\n",
    "    for setting in settings:\n",
    "        filelist, folder1, folder2, alignment = setting[0], setting[1], setting[2], setting[3]\n",
    "        single_benchmark(filelist, folder1, folder2, alignment)\n",
    "        print(\"Finished alignment for: {} {} {} {}\".format(filelist, folder1, folder2, alignment))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments(filelist, alignments_list):\n",
    "    '''create a list of lists to pass into multiple_benchmark based on what alignments we want'''\n",
    "    all_arguments = []\n",
    "    for alignment in alignments_list:\n",
    "        to_concat = [[filelist, 'Mazurkas_median_x1.000', 'Mazurkas_median_x1.000', alignment],\n",
    "                    [filelist, 'Mazurkas_median_x1.260', 'Mazurkas_median_x1.000', alignment],\n",
    "                    [filelist, 'Mazurkas_median_x1.260', 'Mazurkas_median_x0.794', alignment],\n",
    "                    [filelist, 'Mazurkas_median_x1.588', 'Mazurkas_median_x0.794', alignment],\n",
    "                    [filelist, 'Mazurkas_median_x1.588', 'Mazurkas_median_x0.630', alignment],\n",
    "                    [filelist, 'Mazurkas_median_x2.000', 'Mazurkas_median_x0.630', alignment],\n",
    "                    [filelist, 'Mazurkas_median_x2.000', 'Mazurkas_median_x0.500', alignment]]\n",
    "        all_arguments = all_arguments + to_concat\n",
    "    return all_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple_benchmark([['train_toy', 'Mazurkas_median_x1.000', 'Mazurkas_median_x1.000', 'DTW1'],\n",
    "#                     ['train_toy', 'Mazurkas_median_x1.260', 'Mazurkas_median_x1.000', 'DTW1'],\n",
    "#                     ['train_toy', 'Mazurkas_median_x1.260', 'Mazurkas_median_x0.794', 'DTW1'],\n",
    "#                     ['train_toy', 'Mazurkas_median_x1.588', 'Mazurkas_median_x0.794', 'DTW1'],\n",
    "#                     ['train_toy', 'Mazurkas_median_x1.588', 'Mazurkas_median_x0.630', 'DTW1'],\n",
    "#                     ['train_toy', 'Mazurkas_median_x2.000', 'Mazurkas_median_x0.630', 'DTW1'],\n",
    "#                     ['train_toy', 'Mazurkas_median_x2.000', 'Mazurkas_median_x0.500', 'DTW1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW1\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW1\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW1\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW1\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW1\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW1\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW1\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW2\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW2\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW2\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW2\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW2\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW2\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "A path is not possible\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW2\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW3\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW3\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW3\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW3\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW3\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW3\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW3\n"
     ]
    }
   ],
   "source": [
    "DTW_normal = get_arguments('train_toy', ['DTW1', 'DTW2', 'DTW3'])\n",
    "multiple_benchmark(DTW_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW_adds = get_arguments('train_toy', ['DTW1_add3', 'DTW1_add4'])\n",
    "multiple_benchmark(DTW_adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW1_downsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW1_downsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW1_upsampleQuantized\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.000 Mazurkas_median_x1.000 DTW1_upsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x1.000 DTW1_upsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.260 Mazurkas_median_x0.794 DTW1_upsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.794 DTW1_upsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x1.588 Mazurkas_median_x0.630 DTW1_upsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.630 DTW1_upsampleInterpolate\n",
      "Finished alignment for: train_toy Mazurkas_median_x2.000 Mazurkas_median_x0.500 DTW1_upsampleInterpolate\n"
     ]
    }
   ],
   "source": [
    "DTW_samples = get_arguments('train_toy', ['DTW1_downsampleQuantized', 'DTW1_downsampleInterpolate', 'DTW1_upsampleQuantized', 'DTW1_upsampleInterpolate'])\n",
    "multiple_benchmark(DTW_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_benchmark('test_full', '', '', 'DTW1') # two empty arguments since 'Chopin_Mazurka' used. And, need to delete '/' before features in 'featdir1 = Path('{}/features/clean'.format(folder1))'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
