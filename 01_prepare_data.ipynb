{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data üßë‚Äçüç≥"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prepare the data for the alignment task.  We start with the original Mazurka dataset. We then perform time scale modification to normalize all performances within a given Mazurka to be of set duration. We vary this duration among several factors. Beat annotations are then constructed accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations\n",
    "import soundfile as sf\n",
    "from tsm_tools import *\n",
    "from pydub import AudioSegment\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('Chopin_Mazurkas/annotations_beat')\n",
    "AUDIO_ROOT = Path('Chopin_Mazurkas/wav_22050_mono')\n",
    "FEATURES_ROOT = Path('features')\n",
    "TRAIN_FILE = Path('cfg_files/train.txt')\n",
    "TEST_FILE = Path('cfg_files/test.txt')\n",
    "FACTORS = ['0.500','0.630','0.794','1.000','1.260','1.588','2.000']\n",
    "TRAIN_MAZURKAS = ['Chopin_Op017No4','Chopin_Op063No3']\n",
    "TEST_MAZURKAS = ['Chopin_Op024No2','Chopin_Op030No2','Chopin_Op068No3']\n",
    "N_CORES = mp.cpu_count()\n",
    "FEATS_CLEAN_DIR = FEATURES_ROOT / 'clean'\n",
    "DIRECTORIES = ['Chopin_Mazurkas'] + [f\"median_x{factor}\" for factor in FACTORS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Mazurkas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Chopin_Mazurkas folder can be found in '/mnt/data0/Datasets/Chopin_Mazurkas'. You must copy this folder to this working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ -d \"Chopin_Mazurkas\" ] && echo \"already exists\" || cp -r /mnt/data0/Datasets/Chopin_Mazurkas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete exceptional pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Chopin_Op017No4/Chopin_Op017No4_Ginzburg-1957_pid9156-10\n",
      "Removed Chopin_Op068No3_Koczalski-1948_pid9140-05\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove(\"./Chopin_Mazurkas/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Ginzburg-1957_pid9156-10.wav\")\n",
    "    print(\"Removed Chopin_Op017No4/Chopin_Op017No4_Ginzburg-1957_pid9156-10\")\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(\"./Chopin_Mazurkas/wav_22050_mono/Chopin_Op068No3/Chopin_Op068No3_Koczalski-1948_pid9140-05.wav\")\n",
    "    print(\"Removed Chopin_Op068No3_Koczalski-1948_pid9140-05\")\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create filelists text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider all pairwise combinations between performances for a given Mazurka. We allocate 2 Mazukras towards the training set while the remaining 3 Mazukras are used for testing. Once we get the pairs, we select varying amounts for the training set to allow for quicker development and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(piece, filelist, seed=42):\n",
    "    \"\"\"\n",
    "    For a given piece (ie. Chopin_Op017No4), return a list\n",
    "    of tuples of all pair wise combinations between performances.\n",
    "    \"\"\"\n",
    "    performances = []\n",
    "    with open(filelist, 'r') as infile:\n",
    "        for performance in infile:\n",
    "            if piece in performance:\n",
    "                performances.append(performance.split())\n",
    "    pairs = list(combinations(performances, 2))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(pairs)\n",
    "    return pairs\n",
    "\n",
    "def create_file_list(pairs, outdir, limit=None):\n",
    "    \"\"\" Save pairs to *.txt file \"\"\"\n",
    "    if limit:\n",
    "        pairs = pairs[:limit]\n",
    "    with open(outdir, 'w') as o:\n",
    "        for a, b in pairs:\n",
    "            o.write(f\"{a[0]} {b[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = [pair for mazukra in TRAIN_MAZURKAS for pair in get_combinations(mazukra, TRAIN_FILE)]\n",
    "test_pairs = [pair for mazukra in TEST_MAZURKAS for pair in get_combinations(mazukra, TEST_FILE)]\n",
    "\n",
    "# train-toy: randomly select 5 pairs from Op 17 #4\n",
    "create_file_list(train_pairs, 'cfg_files/train_toy.txt', 5)\n",
    "# train-small: randomly select 200 pairs from Op 17 #4\n",
    "create_file_list(train_pairs, 'cfg_files/train_small.txt', 200)\n",
    "# train-medium: includes all (63 choose 2) pairs for Op 17 #4\n",
    "create_file_list(train_pairs, 'cfg_files/train_medium.txt', 1953)\n",
    "# train-full: includes all (63 choose 2) + (88, choose 2) pairs for Op 17 #4 and Op 63 #3\n",
    "create_file_list(train_pairs, 'cfg_files/train_full.txt')\n",
    "# test-full: includes all pairs from the 3 test Mazurkas\n",
    "create_file_list(test_pairs, 'cfg_files/test_full.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find median duration for each Mazurka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Mazurka as a number of performances that represent the same piece. However, they may all differ slightly in time. We first compute the median duration for all 5 pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median():\n",
    "    medians = {}\n",
    "    dirs = glob.glob('Chopin_Mazurkas/wav_22050_mono/*/**/', recursive=True)\n",
    "    for dir in dirs:\n",
    "        piece = os.path.split(os.path.normpath(dir))[-1]\n",
    "        performances = glob.glob(f'{dir}*.wav', recursive=True)\n",
    "        durations = [lb.get_duration(filename=path) for path in performances]\n",
    "        durations.sort()\n",
    "        medians[piece] = durations[len(durations)//2]\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chopin_Op030No2': 87.30149659863946,\n",
       " 'Chopin_Op063No3': 128.22149659863945,\n",
       " 'Chopin_Op068No3': 99.64816326530612,\n",
       " 'Chopin_Op024No2': 136.6748299319728,\n",
       " 'Chopin_Op017No4': 254.92816326530613}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEDIANS = get_median()\n",
    "MEDIANS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform time-scale modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to create 7 different directories corresponding to the 7 chosen duration factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mazurka_directories(factors:str, subseq=None):\n",
    "    for factor in factors:\n",
    "        dir = f'median_x{factor}_subseq{subseq}' if subseq else f'median_x{factor}'\n",
    "        ann_dir = f'{dir}/annotations_beat'\n",
    "        wav_dir = f'{dir}/wav_22050_mono'\n",
    "        for mazurka in TRAIN_MAZURKAS + TEST_MAZURKAS:\n",
    "            ann_piece_dir = f'{ann_dir}/{mazurka}'\n",
    "            wav_piece_dir = f'{wav_dir}/{mazurka}'\n",
    "            Path(ann_piece_dir).mkdir(parents=True, exist_ok=True)\n",
    "            Path(wav_piece_dir).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "create_mazurka_directories(FACTORS, subseq=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to time scale each performance to its Mazurka's median duration times one of 7 chosen duration factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_single(old_wav:str, new_wav:str, median:float, factor:str):\n",
    "    \"\"\"\n",
    "    Take the normal wav file and time warp to its specific factor * median duration.\n",
    "    \"\"\"\n",
    "    y, sr = lb.load(old_wav)\n",
    "    duration = lb.get_duration(y=y, sr=sr)\n",
    "    ratio = float(factor) * (median / duration)\n",
    "    y_mod = tsm_hybrid(y, alpha=ratio) # time scale modification\n",
    "    sf.write(new_wav, y_mod, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timescale_inputs(filelist, piece, factor):\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            if piece in line:\n",
    "                old_wav = f'Chopin_Mazurkas/wav_22050_mono/{line.strip()}.wav'\n",
    "                new_wav = old_wav.replace(\"Chopin_Mazurkas\", f\"median_x{factor}\")\n",
    "                if not os.path.exists(Path(new_wav)):\n",
    "                    inputs.append((old_wav, new_wav, MEDIANS[piece], factor))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time scale modification should take around 20-30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [input for factor in FACTORS for mazurka in TRAIN_MAZURKAS for input in get_timescale_inputs(TRAIN_FILE, mazurka, factor)]\n",
    "inputs += [input for factor in FACTORS for mazurka in TEST_MAZURKAS for input in get_timescale_inputs(TEST_FILE, mazurka, factor)]\n",
    "with mp.Pool(processes = N_CORES) as pool:\n",
    "    pool.starmap(time_scale_single, inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate modified beat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create modified beat files to ensure we correctly evaluate beat alignments. We take the original timestamps and then multiply by the median and factor and then divide by the original_duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_beat_single(in_path_beat, in_path_wav, out_path, num_multiply):\n",
    "    \"\"\"\n",
    "    Modify beat annotations for one given wav file\n",
    "    \"\"\"\n",
    "        \n",
    "    ts = np.array(pd.read_csv(in_path_beat, header=None, sep='\\s+', skiprows=3)[0])\n",
    "    mod_ts = (ts * num_multiply) / lb.get_duration(filename=in_path_wav)\n",
    "    i, header, lines = 0, 0, []\n",
    "\n",
    "    with open(in_path_beat, 'r') as f:\n",
    "        for line in f:\n",
    "            if header < 3: # copy first 3 lines\n",
    "                lines.append(line)\n",
    "                header += 1\n",
    "            else: # modify the rest of the lines\n",
    "                start = mod_ts[i]\n",
    "                end = 0.0 if i + 1 == len(mod_ts) else mod_ts[i+1]\n",
    "                label = line.split('\\t')[-1]\n",
    "                lines.append(f'{start}\\t{end}\\t{label}')\n",
    "                i += 1\n",
    "    with open(out_path, 'w') as o:\n",
    "        for line in lines:\n",
    "            o.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beat_inputs(filelist, piece, factor): # e.g. outdir is 'median_x2.000/annotations_beat/Chopin_Op017No4'\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            if piece in line:\n",
    "                path_to_beat = f'Chopin_Mazurkas/annotations_beat/{line[:-1]}.beat'\n",
    "                path_to_wav = f'Chopin_Mazurkas/wav_22050_mono/{line[:-1]}.wav'\n",
    "                out_path = f'median_x{factor}/annotations_beat/{line[:-1]}.beat'\n",
    "                num_multiply = MEDIANS[piece] * float(factor)\n",
    "                if not os.path.exists(Path(out_path)):\n",
    "                    inputs.append((path_to_beat, path_to_wav, out_path, num_multiply))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [input for factor in FACTORS for mazurka in TRAIN_MAZURKAS for input in get_beat_inputs(TRAIN_FILE, mazurka, factor)]\n",
    "inputs += [input for factor in FACTORS for mazurka in TEST_MAZURKAS for input in get_beat_inputs(TEST_FILE, mazurka, factor)]\n",
    "with mp.Pool(processes = N_CORES) as pool:\n",
    "    pool.starmap(modify_beat_single, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Precompute all chroma features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute all chrome features for the new wav files and save them in each median directory under `features/clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_single(infile, outfile, sr=22050, hop_length=512):\n",
    "    y, sr = lb.core.load(infile, sr=sr)\n",
    "    F = lb.feature.chroma_cqt(y, sr=sr, hop_length=hop_length, norm=2)\n",
    "    np.save(outfile, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_inputs(filelist, dir):\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = dir / FEATS_CLEAN_DIR / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = (dir / Path('wav_22050_mono') / relpath).with_suffix('.wav')\n",
    "            if not os.path.exists(featfile):\n",
    "                inputs.append((audiofile, featfile))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing chroma features should take around 5-10 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [input for dir in DIRECTORIES for input in get_chroma_inputs(TRAIN_FILE, dir)]\n",
    "inputs += [input for dir in DIRECTORIES for input in get_chroma_inputs(TEST_FILE, dir)]  \n",
    "with mp.Pool(processes = N_CORES) as pool:\n",
    "    pool.starmap(compute_chroma_single, inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate subsequence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chopin_Op030No2': 17.46029931972789,\n",
       " 'Chopin_Op063No3': 25.644299319727892,\n",
       " 'Chopin_Op068No3': 19.929632653061226,\n",
       " 'Chopin_Op024No2': 27.33496598639456,\n",
       " 'Chopin_Op017No4': 50.98563265306123}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_mazurka_directories(FACTORS, 20) # 20 for 'subseq20' directories\n",
    "MEDIANS_SUB = {key:value*0.2 for key, value in MEDIANS.items()}\n",
    "MEDIANS_SUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_time(total_dur, target_len):\n",
    "    \"\"\"\n",
    "    Select a random time to get a segment. Everything is in milliseconds.\n",
    "    \"\"\"\n",
    "    start = random.randint(0, math.floor(total_dur-target_len))\n",
    "    end = start + target_len\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new wav and beat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_beat_annotation(in_path_beat, out_path_beat, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Shift beat annotations for one wav file. start_time is in seconds.\n",
    "    \"\"\"\n",
    "    i, header, lines = 0, 0, []\n",
    "    with open(in_path_beat, 'r') as f:\n",
    "        for line in f:\n",
    "            if header < 3: # copy first 3 lines\n",
    "                lines.append(line)\n",
    "                header += 1\n",
    "            else: # modify the rest of the lines\n",
    "                info = line.split('\\t')\n",
    "                start, end, label = float(info[0]), float(info[1]), info[2]\n",
    "                if(end > end_time): # check that we haven't reached the end\n",
    "                    break\n",
    "                elif(start > start_time):\n",
    "                    start, end = start-start_time, end-start_time\n",
    "                    if len(lines) == 3:\n",
    "                        label = f'{label.strip()}-{i}\\n'\n",
    "                    line = f'{start}\\t{end}\\t{label}'\n",
    "                    lines.append(line)\n",
    "                i += 1\n",
    "    with open(out_path_beat, 'w') as o:\n",
    "        for line in lines:\n",
    "            o.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_subseq_single(path_to_wav, out_path_wav, median, factor, outdir):\n",
    "    \"\"\"\n",
    "    Modify a single wav and beat file pair\n",
    "    \"\"\"\n",
    "        \n",
    "    # cut the .wav file into target segment\n",
    "    new_audio = AudioSegment.from_wav(path_to_wav) # load old audio\n",
    "    old_duration = new_audio.duration_seconds*1000\n",
    "    start_time, end_time = get_random_time(old_duration, median*1000*float(factor)) # calculate time to modify to\n",
    "    new_audio = new_audio[start_time:end_time] # cut the .wav file\n",
    "\n",
    "    # save to new .wav file\n",
    "    with open(out_path_wav, 'wb') as f:\n",
    "        new_audio.export(f, format='wav')\n",
    "    \n",
    "    # make beat file\n",
    "    in_path_beat = path_to_wav.replace('wav_22050_mono', 'annotations_beat').replace('.wav', '.beat')\n",
    "    out_path_beat = f'{outdir}{in_path_beat[22:]}'\n",
    "    shift_beat_annotation(in_path_beat, out_path_beat, start_time/1000, end_time/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subseq_inputs(filelist, piece, median_subseq, factor):\n",
    "    inputs, indir, outdir = [], f'median_x{factor}', f'median_x{factor}_sub20'\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            if piece in line:\n",
    "                path_to_wav = f'{indir}/wav_22050_mono/{line[:-1]}.wav'\n",
    "                out_path_wav = f'{outdir}{path_to_wav[22:]}'\n",
    "                if not os.path.exists(out_path_wav):\n",
    "                    inputs.append((path_to_wav, out_path_wav, MEDIANS_SUB[piece], factor, outdir))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [input for factor in FACTORS for mazurka in TRAIN_MAZURKAS for input in get_subseq_inputs(TRAIN_FILE, mazurka, factor)]\n",
    "inputs += [input for factor in FACTORS for mazurka in TEST_MAZURKAS for input in get_subseq_inputs(TEST_FILE, mazurka, factor)]\n",
    "with mp.Pool(processes = N_CORES) as pool:\n",
    "    pool.starmap(modify_subseq_single, inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute chroma features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_DIRECTORIES = ['median_x0.500_sub20', 'median_x0.630_sub20', 'median_x0.794_sub20', 'median_x1.000_sub20', 'median_x1.260_sub20', 'median_x1.588_sub20', 'median_x2.000_sub20']\n",
    "inputs = [input for dir in SUB_DIRECTORIES for input in get_chroma_inputs(TRAIN_FILE, dir)]\n",
    "inputs += [input for dir in SUB_DIRECTORIES for input in get_chroma_inputs(TEST_FILE, dir)]  \n",
    "with mp.Pool(processes = N_CORES) as pool:\n",
    "    pool.starmap(compute_chroma_single, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
