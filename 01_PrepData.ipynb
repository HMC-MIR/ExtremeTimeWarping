{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prep the data for the alignment task.  This includes computing audio features and generating a query list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('Chopin_Mazurkas/annotations_beat')\n",
    "AUDIO_ROOT = Path('Chopin_Mazurkas/wav_22050_mono')\n",
    "FEATURES_ROOT = Path('features')\n",
    "train_files = Path('cfg_files/filelist.train.txt')\n",
    "test_files = Path('cfg_files/filelist.test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FEATURES_ROOT):\n",
    "    os.mkdir(FEATURES_ROOT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train-toy, Train-small, Train-medium, Train-full, Test-full filelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_internal_datasets(num_pairs, filelist, piece, outdir): # piece is e.g. 'Chopin_Op017No4'\n",
    "    '''creates a file with num_pairs combiantions of file names in piece'''\n",
    "    # load file names from original file list\n",
    "    total_files = []\n",
    "    with open(filelist, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if piece in line:\n",
    "                total_files.append(line)\n",
    "    # generate all pairs\n",
    "    all_pairs = list(combinations(total_files, 2))\n",
    "    subset = random.sample(range(0, len(all_pairs)), num_pairs) # select num_pairs random pairs from all_pairs\n",
    "    # write to outfile\n",
    "    with open(outdir,'a') as outfile:\n",
    "        for index in subset:\n",
    "            item1, item2 = all_pairs[index]\n",
    "            outfile.write(item1[:-1]+' '+item2)   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_allpairs_datasets(filelist, piece, outdir):\n",
    "    '''creates a file with all possible combinations of file names in piece'''\n",
    "    total_files = []\n",
    "    with open(filelist, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if piece in line:\n",
    "                total_files.append(line)\n",
    "    # generate all pairs\n",
    "    all_pairs = list(combinations(total_files, 2))\n",
    "    # write to outfile\n",
    "    with open(outdir,'a') as outfile:\n",
    "        for pair in all_pairs:\n",
    "            item1, item2 = pair[0], pair[1]\n",
    "            outfile.write(item1[:-1]+' '+item2)   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE TRAIN DATASETS\n",
    "# Train-toy: randomly select 5 pairs from Op 17 #4\n",
    "create_internal_datasets(5, train_files, 'Chopin_Op017No4', 'cfg_files/filelist.train_toy.txt')\n",
    "\n",
    "# Train-small: randomly select 200 pairs from Op 17 #4\n",
    "create_internal_datasets(200, train_files, 'Chopin_Op017No4', 'cfg_files/filelist.train_small.txt')\n",
    "\n",
    "# Train-medium: includes all (63 choose 2) pairs for Op 17 #4\n",
    "create_internal_datasets(1953, train_files, 'Chopin_Op017No4', 'cfg_files/filelist.train_medium.txt')\n",
    "\n",
    "# Train-full: includes all (63 choose 2) + (88, choose 2) pairs for Op 17 #4 and Op 63 #3\n",
    "create_internal_datasets(1953, train_files, 'Chopin_Op017No4', 'cfg_files/filelist.train_full.txt')\n",
    "create_internal_datasets(3828, train_files, 'Chopin_Op063No3', 'cfg_files/filelist.train_full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE TEST DATASETS\n",
    "# Test-full: includes all pairs from the 3 test Mazurkas\n",
    "create_allpairs_datasets(test_files, 'Chopin_Op024No2', 'cfg_files/filelist.test_full.txt')\n",
    "create_allpairs_datasets(test_files, 'Chopin_Op030No2', 'cfg_files/filelist.test_full.txt')\n",
    "create_allpairs_datasets(test_files, 'Chopin_Op068No3', 'cfg_files/filelist.test_full.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate query list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate a file containing each pair of files to be aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_list(filelist, outfile): # Does what we already did before\n",
    "    \n",
    "    # group files by piece\n",
    "    d = {}\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('/')\n",
    "            assert len(parts) == 2\n",
    "            piece, fileid = parts\n",
    "            if piece not in d:\n",
    "                d[piece] = []\n",
    "            d[piece].append(fileid)\n",
    "            \n",
    "    # print out all pairings\n",
    "    with open(outfile, 'w') as fout:\n",
    "        for piece in d:\n",
    "            num_recordings = len(d[piece])\n",
    "            for i in range(num_recordings):\n",
    "                fileid1 = d[piece][i]\n",
    "                for j in range(i+1, num_recordings):\n",
    "                    fileid2 = d[piece][j]\n",
    "                    line = f'{piece}/{fileid1} {piece}/{fileid2}\\n'\n",
    "                    fout.write(line)\n",
    "                    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries = 'cfg_files/query.train.list'\n",
    "test_queries = 'cfg_files/query.test.list'\n",
    "generate_query_list(train_files, train_queries)\n",
    "generate_query_list(test_files, test_queries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct 7 modified benchmark datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find median duration for each Mazurka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(filelist, piece):\n",
    "    '''get median duration of recordings in one Mazurka folder'''\n",
    "    lengths = []\n",
    "    with open(filelist, 'r') as cfg_file:\n",
    "        # for each line, if line contains the Mazurka\n",
    "        for line in cfg_file:\n",
    "            if piece in line:\n",
    "                #   make path to .wav file\n",
    "                path_to_wav = 'Chopin_Mazurkas/wav_22050_mono/{}.wav'.format(line[:-1])\n",
    "                #   calculate duration\n",
    "                duration = lb.get_duration(filename=path_to_wav)\n",
    "                #   append to list\n",
    "                lengths.append(duration)\n",
    "\n",
    "    lengths.sort()\n",
    "    median = lengths[len(lengths)//2]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chopin_Op017No4_MEDIAN = get_median('cfg_files/filelist.train.txt','Chopin_Op017No4')\n",
    "Chopin_Op063No3_MEDIAN = get_median('cfg_files/filelist.train.txt','Chopin_Op063No3')\n",
    "Chopin_Op024No2_MEDIAN = get_median('cfg_files/filelist.test.txt','Chopin_Op024No2')\n",
    "Chopin_Op030No2_MEDIAN = get_median('cfg_files/filelist.test.txt','Chopin_Op030No2')\n",
    "Chopin_Op068No3_MEDIAN = get_median('cfg_files/filelist.test.txt','Chopin_Op068No3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create separate directories for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mazurka_directories(time_modify):\n",
    "    '''create separate directories for each time scale modification'''\n",
    "    for item in time_modify:\n",
    "        dir = 'Mazurkas_median_x{}'.format(item)\n",
    "        ann_dir = '{}/annotations_beat'.format(dir)\n",
    "        wav_dir = '{}/wav_22050_mono'.format(dir)\n",
    "        for mazurka in ['Chopin_Op017No4','Chopin_Op024No2','Chopin_Op030No2','Chopin_Op063No3','Chopin_Op068No3']:\n",
    "            ann_piece_dir = '{}/{}'.format(ann_dir, mazurka)\n",
    "            wav_piece_dir = '{}/{}'.format(wav_dir, mazurka)\n",
    "            if not os.path.exists(ann_piece_dir):\n",
    "                os.makedirs(ann_piece_dir)\n",
    "            if not os.path.exists(wav_piece_dir):\n",
    "                os.makedirs(wav_piece_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['1.000','0.500','0.630','0.794','1.260','1.588','2.000']\n",
    "create_mazurka_directories(factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform time-scale modification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "from tsm_tools import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_batch(filelist, piece, median_duration, factor, outdir, n_cores):\n",
    "    '''time-scale modify for all .wav files for one mazurka for one factor'''\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as cfg_file:\n",
    "        for line in cfg_file:\n",
    "            if piece in line:\n",
    "                # make path to .wav file\n",
    "                path_to_wav = 'Chopin_Mazurkas/wav_22050_mono/{}.wav'.format(line[:-1])\n",
    "                inputs.append((path_to_wav, median_duration, factor, outdir))\n",
    "    \n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(time_scale_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_single(path_to_wav, median_duration, factor, outdir):\n",
    "    '''time-scale modify for one .wav file'''\n",
    "    y, sr = lb.load(path_to_wav)\n",
    "    # do time scale modification\n",
    "    old_duration = lb.get_duration(y=y, sr=sr)\n",
    "    ratio = (median_duration*factor) / old_duration\n",
    "    y_mod = tsm_hybrid(y, alpha=ratio)\n",
    "    # save to new .wav file\n",
    "    new_path_to_wav = '{}{}'.format(outdir, path_to_wav[15:]) # e.g. 'Mazurkas_median_x1.000/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Kitain-1937_pid9163-02.wav'\n",
    "    #lb.output.write_wav(new_path_to_wav, y, sr)\n",
    "    sf.write(new_path_to_wav, y_mod, sr)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_scale_by_mazurka(filelist, piece, median_duration, factors):\n",
    "    '''time-scale modify by all factors with one mazurka'''\n",
    "    for factor in factors:\n",
    "        time_scale_batch(filelist, piece, median_duration, float(factor),'Mazurkas_median_x{}'.format(factor), 24)\n",
    "        print(\"Done with Mazurkas_median_x{}/{}\".format(factor, piece))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(train_files,'Chopin_Op017No4',Chopin_Op017No4_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(train_files,'Chopin_Op063No3',Chopin_Op063No3_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(test_files,'Chopin_Op024No2',Chopin_Op024No2_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(test_files,'Chopin_Op030No2',Chopin_Op030No2_MEDIAN,factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scale_by_mazurka(test_files,'Chopin_Op068No3',Chopin_Op068No3_MEDIAN,factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate .beat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestamps(annotfile):\n",
    "    df = pd.read_csv(annotfile, header=None, sep='\\s+', skiprows=3)\n",
    "    return np.array(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beat_annotation(in_path_beat, in_path_wav, out_path, num_multiply): # num_multiply should be median*factor\n",
    "    '''modifies beat annotations for one .wav file'''\n",
    "    # load .wav file to get original duration\n",
    "    real_duration = lb.get_duration(filename=in_path_wav)\n",
    "    # (median*factor)/real_dur\n",
    "    original_ts = getTimestamps(in_path_beat)\n",
    "    modified_ts = (original_ts*num_multiply)/real_duration\n",
    "    index = 0\n",
    "    curr_read = 0\n",
    "    new_lines = []\n",
    "    with open(in_path_beat, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if curr_read < 3: # copy first 3 lines\n",
    "                new_lines.append(line)\n",
    "                curr_read += 1\n",
    "                continue\n",
    "            else: # modify the rest of the lines\n",
    "                label = line.split('\\t')[-1]\n",
    "                if index+1 == len(modified_ts):\n",
    "                    curr_start, curr_end = modified_ts[index], 0.0\n",
    "                else:\n",
    "                    curr_start, curr_end = modified_ts[index], modified_ts[index+1]\n",
    "                new_string = '{}\\t{}\\t{}'.format(curr_start, curr_end, label)\n",
    "                new_lines.append(new_string)\n",
    "                index += 1\n",
    "    with open(out_path, 'w') as outfile:\n",
    "        for line in new_lines:\n",
    "            outfile.write(line)\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_beat_annotation('Chopin_Mazurkas/annotations_beat/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.beat', 'Chopin_Mazurkas/wav_22050_mono/Chopin_Op017No4/Chopin_Op017No4_Weissenberg-1971_pid9052b-09.wav', 'hello.beat', Chopin_Op017No4_MEDIAN*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beat_annotation_batch(filelist, piece, median_duration, factor, outdir, n_cores): # e.g. outdir is 'Mazurkas_median_x2.000/annotations_beat/Chopin_Op017No4'\n",
    "    '''modifies beat annotations for all .wav files for one Mazurka for one factor'''\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as cfg_file:\n",
    "        for line in cfg_file:\n",
    "            if piece in line:\n",
    "                path_to_beat = 'Chopin_Mazurkas/annotations_beat/{}.beat'.format(line[:-1])\n",
    "                path_to_wav = 'Chopin_Mazurkas/wav_22050_mono/{}.wav'.format(line[:-1])\n",
    "                out_path = 'Mazurkas_median_x{}/annotations_beat/{}.beat'.format(factor, line[:-1])\n",
    "                num_multiply = median_duration*float(factor)\n",
    "                inputs.append((path_to_beat, path_to_wav, out_path, num_multiply))\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(create_beat_annotation, inputs)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_beat_annotation_batch(train_files, 'Chopin_Op017No4', Chopin_Op017No4_MEDIAN, '2.000', 'Mazurkas_median_x2.000/annotations_beat/Chopin_Op017No4', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_annotation_by_mazurka(filelist, piece, median_duration, factors):\n",
    "    '''modifies beat annotations by all factors with one mazurka'''\n",
    "    for factor in factors:\n",
    "        create_beat_annotation_batch(filelist, piece, median_duration, factor, 'Mazurkas_median_x{}/annotations_beat/{}'.format(factor, piece), 24)\n",
    "        print(\"Done with Mazurkas_median_x{}/annotations_beat/{}\".format(factor, piece))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_annotation_by_mazurka(train_files, 'Chopin_Op017No4', Chopin_Op017No4_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(train_files, 'Chopin_Op063No3', Chopin_Op063No3_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(test_files, 'Chopin_Op024No2', Chopin_Op024No2_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(test_files, 'Chopin_Op030No2', Chopin_Op030No2_MEDIAN, factors)\n",
    "beat_annotation_by_mazurka(test_files, 'Chopin_Op068No3', Chopin_Op068No3_MEDIAN, factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features on clean audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute features on the audio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute features on the 'Chopin_Mazurkas' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_single(infile, outfile, sr = 22050, hop_length=512):\n",
    "    y, sr = lb.core.load(infile, sr = sr)\n",
    "    #F = lb.feature.chroma_cens(y, sr=sr, hop_length=hop_length)\n",
    "    F = lb.feature.chroma_cqt(y, sr=sr, hop_length=hop_length, norm=2)\n",
    "    np.save(outfile, F)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_batch(filelist, outdir, n_cores):\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = outdir / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = (AUDIO_ROOT / relpath).with_suffix('.wav')\n",
    "            if os.path.exists(featfile):\n",
    "                print(f\"Skipping {featfile}\")\n",
    "            else:\n",
    "                inputs.append((audiofile, featfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(compute_chroma_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_CLEAN_DIR = FEATURES_ROOT / 'clean'\n",
    "compute_chroma_batch(train_files, FEATS_CLEAN_DIR, 24)\n",
    "compute_chroma_batch(test_files, FEATS_CLEAN_DIR, 24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute features on the modified median directories e.g. 'Mazurkas_median_x0.500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_median(filelist, median_dir, outdir, n_cores): # outdir should be 'features/clean'\n",
    "    '''compute features for each median directory e.g. for all .wav files in 'Mazurkas_median_x0.500' '''\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = median_dir / outdir / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = (median_dir / Path('wav_22050_mono') / relpath).with_suffix('.wav')\n",
    "            if os.path.exists(featfile):\n",
    "                print(f\"Skipping {featfile}\")\n",
    "            else:\n",
    "                inputs.append((audiofile, featfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(compute_chroma_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_CLEAN_DIR = FEATURES_ROOT / 'clean'\n",
    "median_directories = ['Mazurkas_median_x0.500', 'Mazurkas_median_x0.630', 'Mazurkas_median_x0.794', 'Mazurkas_median_x1.000', 'Mazurkas_median_x1.260', 'Mazurkas_median_x1.588', 'Mazurkas_median_x2.000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute chromas for each directory\n",
    "for median_dir in median_directories:\n",
    "    compute_chroma_median(train_files, median_dir, FEATS_CLEAN_DIR, 24)\n",
    "    compute_chroma_median(test_files, median_dir, FEATS_CLEAN_DIR, 24)\n",
    "    print(\"Finished generating features for {}\".format(median_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
